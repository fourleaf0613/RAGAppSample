import os
import re
import json
import logging
import random
import string
import tempfile
from datetime import datetime
from openai import AzureOpenAI
from dotenv import load_dotenv
# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

import streamlit as st
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.cosmos import PartitionKey
from azure.cosmos.cosmos_client import CosmosClient
from azure.storage.blob import BlobServiceClient

# ä»–ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from preparedata import process_file

# envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’å–å¾—
client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION")
)

# Azure OpenAI Service ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
AZURE_OPENAI_CHAT_MODEL = os.getenv("AZURE_OPENAI_CHAT_MODEL")
AZURE_OPENAI_EMBED_MODEL = os.getenv("AZURE_OPENAI_EMBED_MODEL")
AZURE_OPENAI_CHAT_MAX_TOKENS = int(os.getenv("AZURE_OPENAI_CHAT_MAX_TOKENS", "1000"))

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ Azure Cosmos DB ã®æ¥ç¶šæ–‡å­—åˆ—ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åã‚’å–å¾—ã™ã‚‹
COSMOS_CONNECTION_STRING = os.getenv("COSMOS_CONNECTION_STRING")
COSMOS_DB_NAME = os.getenv("COSMOS_DB_NAME")
COSMOS_CONTAINER_NAME_CHAT = os.getenv("COSMOS_CONTAINER_NAME_CHAT")

# Cosmos DB ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ç”Ÿæˆã™ã‚‹
cosmos_client = CosmosClient.from_connection_string(COSMOS_CONNECTION_STRING)
database = cosmos_client.get_database_client(COSMOS_DB_NAME)
database.create_container_if_not_exists(
    id=COSMOS_CONTAINER_NAME_CHAT,
    partition_key=PartitionKey(path=f"/id"),
)
container = database.get_container_client(COSMOS_CONTAINER_NAME_CHAT)

# Azure AI Search ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
AI_SEARCH_ENDPOINT = os.getenv("AI_SEARCH_ENDPOINT")
AI_SEARCH_KEY = os.getenv("AI_SEARCH_KEY")
AI_SEARCH_API_VERSION = os.getenv("AI_SEARCH_API_VERSION", "2023-10-01-Preview")
AI_SEARCH_INDEX_NAME = os.getenv("AI_SEARCH_INDEX_NAME")
AI_SEACH_SEMANTIC = os.getenv("AI_SEACH_SEMANTIC")
top_k_temp = 10  # æ¤œç´¢çµæœã®ä¸Šä½ä½•ä»¶ã‚’è¡¨ç¤ºã™ã‚‹ã‹

# Azure Blob Storage ã®æƒ…å ±ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹
BLOB_STORAGE_CONNECTION_STRING = os.getenv("BLOB_STORAGE_CONNECTION_STRING")
BLOB_CONTAINER_NAME = os.getenv("BLOB_CONTAINER_NAME")

# Blob Storage ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
blob_service_client = BlobServiceClient.from_connection_string(BLOB_STORAGE_CONNECTION_STRING)
blob_container_client = blob_service_client.get_container_client(BLOB_CONTAINER_NAME)
# ã‚³ãƒ³ãƒ†ãƒŠãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
try:
    blob_container_client.get_container_properties()
except Exception:
    blob_container_client.create_container()

# OpenAIã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã‚’è¡Œã†ã€‚
SystemPrompt = """ã‚ãªãŸã¯ã€ä¼šç¤¾ã®å¾“æ¥­å“¡ãŒç¤¾å†…ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹è³ªå•ã‚’ã™ã‚‹éš›ã«æ”¯æ´ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®åˆ¶ç´„ã‚’å¿…ãšå®ˆã£ã¦ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã¯èµ·ã“ã•ãªã„ã§ãã ã•ã„ã€‚
é­…åŠ›çš„ã§ä¸å¯§ãªå›ç­”ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
æœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§ã˜ã£ãã‚Šèª­ã‚“ã§å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„ã€‚æœ€é«˜ã®ä»•äº‹ã‚’ã—ã¾ã—ã‚‡ã†

# åˆ¶ç´„ 
ãƒ»ä»¥ä¸‹ã®Sources(æƒ…å ±æº)ã«è¨˜è¼‰ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚å¿…ãšæƒ…å ±æºã«è¨˜è¼‰ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸºã«å›ç­”ã‚’ä½œã£ã¦ãã ã•ã„
ãƒ»ååˆ†ãªæƒ…å ±ãŒãªã„å ´åˆã¯ã€ã‚ã‹ã‚‰ãªã„ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚
ãƒ»ä»¥ä¸‹ã®Sources(æƒ…å ±æº)ã‚’ä½¿ç”¨ã—ãªã„å›ç­”ã¯ç”Ÿæˆã—ãªã„ã§ãã ã•ã„ ã€‚å›ç­”ã«ã¯å½¹å‰²(userã‚„assistantãªã©)ã®æƒ…å ±ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒä¸æ˜ç­ãªå ´åˆã¯ã€æ˜ç¢ºåŒ–ã®ãŸã‚ã«ãƒ¦ãƒ¼ã‚¶ã«è³ªå•ã—ã¦ãã ã•ã„ã€‚
ãƒ»Sourcesã«ã¯ã€åå‰ã®å¾Œã«ã‚³ãƒ­ãƒ³ã¨å®Ÿéš›ã®æƒ…å ±ãŒç¶šãã¾ã™ã€‚å›ç­”ã§ä½¿ç”¨ã™ã‚‹å„äº‹å®Ÿã«ã¤ã„ã¦ã€å¸¸ã«Sourcesã®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
  æƒ…å ±æºã‚’å‚ç…§ã™ã‚‹ã«ã¯ã€å„Contentæƒ…å ±ã®å‰æ®µã«ã‚ã‚‹filenameã®æƒ…å ±ã‚’åæ˜ ã—ã¦ãã ã•ã„ã€‚è§’ã‹ã£ã“ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
  Sourceså‚ç…§ãƒ«ãƒ¼ãƒ«ï¼š[filename] ã€€Sourceså‡ºåŠ›ä¾‹ï¼š[info1.txt]
ãƒ»Sourcesã‚’çµ„ã¿åˆã‚ã›ãªã„ã§ãã ã•ã„ã€‚å„Sourcesã‚’å€‹åˆ¥ã«ãƒªã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼š[info1.txt],[info1.txt]
ãƒ»æ—¥æœ¬èªã®è³ªå•ã®å ´åˆã¯ã€æ—¥æœ¬èªã§å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚è‹±èªã§ã®è³ªå•ã®å ´åˆã¯ã€è‹±èªã§å›ç­”ã‚’ä½œæˆã—å›ç­”ã—ã¦ãã ã•ã„ã€‚    
"""

# Function to generate embeddings for title and content fields, also used for query embeddings
def generate_embeddings(text, text_limit=7000):
    # Clean up text (e.g. line breaks, )
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'[\n\r]+', ' ', text).strip()
    # Truncate text if necessary
    if len(text) > text_limit:
        logging.warning("Token limit exceeded maximum length, truncating...")
        text = text[:text_limit]

    response = client.embeddings.create(model=AZURE_OPENAI_EMBED_MODEL, input=text)
    embeddings = response.data[0].embedding
    return embeddings

def query_vector_index(index_name, query, searchtype, top_k_parameter):
    vector = generate_embeddings(query)
    search_client = SearchClient(AI_SEARCH_ENDPOINT, index_name, AzureKeyCredential(AI_SEARCH_KEY))
    vector_query = VectorizedQuery(vector=vector, fields="contentVector")
    # searchtypeãŒvector_onlyã®å ´åˆã¯ã€search_textã‚’Noneã«ã™ã‚‹
    if searchtype == "Vector_only":
        search_text = None
    # searchtypeãŒvector_onlyä»¥å¤–ã®å ´åˆã¯ã€search_textã«queryã‚’è¨­å®šã™ã‚‹
    else:
        search_text = query

    # searchtypeãŒvector_onlyã‚‚ã—ãã¯Hybridã®å ´åˆ
    if searchtype == "Vector_only" or searchtype == "Hybrid":
        results = search_client.search(search_text=search_text, vector_queries=[vector_query], top=int(top_k_parameter))
    # searchtypeãŒFullã®å ´åˆ
    else:
        results = search_client.search(search_text=search_text, vector_queries=[vector_query], top=int(top_k_parameter),
                                       query_type='semantic', semantic_configuration_name=AI_SEACH_SEMANTIC)

    return results

# chatå±¥æ­´ã‚’ Cosmos DB ã«ä¿å­˜ã™ã‚‹
def add_to_cosmos(item):
    container.upsert_item(item)

def randomname(n):
    randlst = [random.choice(string.ascii_letters + string.digits) for i in range(n)]
    return ''.join(randlst)

def upload_file_to_blob_storage(uploaded_file):
    blob_client = blob_container_client.get_blob_client(uploaded_file.name)
    blob_client.upload_blob(uploaded_file.getbuffer(), overwrite=True)
    print(f"Uploaded {uploaded_file.name} to Blob Storage.")

def download_file_from_blob_storage(file_name):
    blob_client = blob_container_client.get_blob_client(file_name)
    download_file_path = os.path.join(tempfile.gettempdir(), file_name)
    with open(download_file_path, "wb") as download_file:
        download_data = blob_client.download_blob()
        download_data.readinto(download_file)
    print(f"Downloaded {file_name} from Blob Storage to {download_file_path}.")
    return download_file_path

def process_uploaded_file(uploaded_file, index_name):
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Blob Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    upload_file_to_blob_storage(uploaded_file)

    # Blob Storageã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    downloaded_file_path = download_file_from_blob_storage(uploaded_file.name)

    # Args ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©
    class Args:
        def __init__(self):
            self.blob = None

    # args ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€blob ã‚’è¨­å®š
    args = Args()
    args.blob = 1  # ã¾ãŸã¯é©åˆ‡ãªå€¤

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    process_file(downloaded_file_path, index_name, args)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    os.remove(downloaded_file_path)

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
    st.session_state['file_processed'] = True

def main():
    # Set page title and icon
    st.set_page_config(page_title="RAG App", page_icon="ğŸ’¬", layout="wide")

    # Display title
    st.markdown("# RAG App")

    # Display explanation in sidebar
    st.sidebar.header("Sample RAG App")
    st.sidebar.markdown("RAGã‚’æ¤œè¨¼ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã®åˆæœŸåŒ–
    if "session_id" not in st.session_state:
        st.session_state['session_id'] = randomname(10)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state['messages'] = []

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã®åˆæœŸåŒ–
    if 'file_processed' not in st.session_state:
        st.session_state['file_processed'] = False

    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå ´åˆã€ãƒãƒ£ãƒƒãƒˆã¨st.text_input,promptallã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã€‚
    if st.sidebar.button("Clear Chat"):
        st.session_state['messages'] = []
        promptall = ""
        # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ç”Ÿæˆã—ã¦ä¿å­˜
        st.session_state['session_id'] = randomname(10)
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state['file_processed'] = False
        # ã‚¢ãƒ—ãƒªã‚’å†å®Ÿè¡Œã—ã¦ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ãƒªã‚»ãƒƒãƒˆ
        st.rerun()
        
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®åå‰ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã§æŒ‡å®šã™ã‚‹ã€‚indexnameã®è¨­å®š
    indexname = st.sidebar.text_input("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å", AI_SEARCH_INDEX_NAME)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’è¿½åŠ 
    st.sidebar.markdown("### ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    file_uploader_placeholder = st.sidebar.empty()

    if not st.session_state['file_processed']:
        with file_uploader_placeholder:
            uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=['pdf', 'txt'])
            if uploaded_file is not None:
                with st.spinner('ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™...'):
                    process_uploaded_file(uploaded_file, indexname)
                st.success(f"ãƒ•ã‚¡ã‚¤ãƒ« '{uploaded_file.name}' ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
                st.session_state['file_processed'] = True
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’å‰Šé™¤
                file_uploader_placeholder.empty()
                st.rerun()
    else:
        st.sidebar.write("ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‡¦ç†æ¸ˆã¿ã§ã™ã€‚'Clear Chat'ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒªã‚»ãƒƒãƒˆã§ãã¾ã™ã€‚")

    # Set Search parameters in sidebar
    st.sidebar.markdown("### Search Parameters")

    # æ¤œç´¢çµæœã®ä¸Šä½ä½•ä»¶ã‚’å¯¾è±¡ã¨ã™ã‚‹ã‹ã‚’è¨­å®šã™ã‚‹ã€‚top_k_parameterã®è¨­å®šã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã§æŒ‡å®šã™ã‚‹ã€‚
    top_k_parameter = st.sidebar.text_input("æ¤œç´¢çµæœå¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°", str(top_k_temp))

    # æ¤œç´¢ã®ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã™ã‚‹ã€‚vector_only or Hybrid or Fullã®é¸æŠã€‚1ã¤ã®é¸æŠå¯èƒ½
    search_type = st.sidebar.radio("æ¤œç´¢ã‚¿ã‚¤ãƒ—", ("Semantic_Hybrid", "Vector_only", "Hybrid"))


    # Set ChatGPT parameters in sidebar
    st.sidebar.markdown("### ChatGPT Parameters")
    Temperature_temp = st.sidebar.slider("Temperature", 0.0, 1.0, 0.0, 0.01)

    # SystemRoleã‚’å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã§æŒ‡å®šã™ã‚‹
    SystemRole = st.sidebar.text_area("System Role", SystemPrompt)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    for message in messages:
        # roleãŒassistantã ã£ãŸã‚‰ã€assistantã®chat_messageã‚’ä½¿ã†
        if message['role'] == 'assistant':
            with st.chat_message('assistant'):
                st.markdown(message['content'])
        # roleãŒuserã ã£ãŸã‚‰ã€userã®chat_messageã‚’ä½¿ã†
        elif message['role'] == 'user':
            with st.chat_message('user'):
                st.markdown(message['content'])
        else:  # ä½•ã‚‚å‡ºåŠ›ã—ãªã„
            pass

    # Add system role to session state
    if SystemRole:
        # æ—¢ã«roleãŒsystemã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚‹å ´åˆã¯ã€è¿½åŠ ã—ãªã„ã€‚ãªã„å ´åˆã¯è¿½åŠ ã™ã‚‹ã€‚
        if not any(message["role"] == "system" for message in st.session_state.messages):
            st.session_state.messages.append({"role": "system", "content": SystemRole})

    # Azure AI Search ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹
    credential = AzureKeyCredential(AI_SEARCH_KEY)
    index_client = SearchIndexClient(
        endpoint=AI_SEARCH_ENDPOINT,
        credential=credential,
        api_version=AI_SEARCH_API_VERSION,
    )

    # ãƒ¦ãƒ¼ã‚¶ã‹ã‚‰ã®å…¥åŠ›ã‚’å–å¾—ã™ã‚‹
    if user_input := st.chat_input("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
        # æ¤œç´¢ã™ã‚‹ã€‚search_fieldsã¯contentã‚’å¯¾è±¡ã«æ¤œç´¢ã™ã‚‹
        results = query_vector_index(indexname, user_input, search_type, top_k_parameter)

        # å¤‰æ•°ã‚’åˆæœŸåŒ–ã™ã‚‹
        prompt_source = ""
        sourcetemp = []

        with st.chat_message("user"):
            st.markdown(user_input)

        # st.session_state.messagesã®å†…å®¹ã‚’å¹³æ–‡ã«ã—ã¦ã€conversion_historyã«ä»£å…¥ã™ã‚‹ã€‚RoleãŒSystemã®å ´åˆã¯ã€ä»£å…¥ã—ãªã„ã€‚
        # å„messageã®contentã‚’æ”¹è¡Œã—ã¦è¡¨ç¤ºã™ã‚‹ã€‚roleã‚‚ã‚ã‹ã‚‹ã‚ˆã†ã«ä»£å…¥ã™ã‚‹
        conversion_history = ""
        for message in st.session_state.messages:
            if message['role'] == 'system':
                pass
            else:
                conversion_history += message['role'] + ": " + message['content'] + "\n\n"

        # resultsã‹ã‚‰å„resultã®çµæœã‚’å¤‰æ•°prompt_sourceã«ä»£å…¥ã™ã‚‹ã€‚filepathã¨contentã®æƒ…å ±ã‚’ä»£å…¥ã™ã‚‹ã€‚
        for result in results:
            Score = result['@search.score']
            filename = result['fileName'] + "-" + str(result['chunkNo'])
            chunkNo = result['chunkNo']
            content = result['content']
            title = result['title']
            Keywords = result['keywords']

            # å¤‰æ•°prompt_sourceã«å„å¤‰æ•°ã®å€¤ã‚’è¿½åŠ ã™ã‚‹
            prompt_source += f"## filename: {filename}\n\n  ### score: {Score}\n\n  ### content: \n\n {content}\n\n"

            # filename, title, contentã®å†…å®¹ã‚’markdownå½¢å¼ã§sourcetempé…åˆ—ã«æ ¼ç´ã™ã‚‹
            # sourcetempã¯resultã®å†…å®¹ãŒå¤‰ã‚ã‚‹åº¦ã«é…åˆ—ã‚’å¤‰æ›´ã™ã‚‹
            sourcetemp.append(f"## filename: {filename}\n\n  ### title: {title}\n\n  ### content: \n\n {content}\n\n")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã™ã‚‹
        promptall = SystemRole + "\n\n# Sources(æƒ…å ±æº): \n\n" + prompt_source + "# ä»Šã¾ã§ã®ä¼šè©±å±¥æ­´ï¼š\n\n" + conversion_history + "# å›ç­”ã®ç”Ÿæˆ\n\nãã‚Œã§ã¯ã€åˆ¶ç´„ã‚’è¸ã¾ãˆã¦æœ€é«˜ã®å›ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚ãªãŸãªã‚‰ã§ãã‚‹ï¼"
        st.session_state.messages.append({"role": "user", "content": user_input})

        # expanderã‚’ä½œæˆã™ã‚‹
        with st.sidebar.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¡¨ç¤º"):
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹
            st.markdown(promptall)

        #Jsonå½¢å¼ã®messagestempå¤‰æ•°ã«roleã‚’userã¨ã—ã¦ã€promptallã‚’ä»£å…¥ã™ã‚‹
        messagestemp = []
        messagestemp.append({"role": "system", "content": promptall})
        messagestemp.append({"role": "user", "content": user_input})

        with st.chat_message("assistant"):
            output = client.chat.completions.create(
                model=AZURE_OPENAI_CHAT_MODEL,
                messages=messagestemp,
                temperature=Temperature_temp,
                max_tokens=AZURE_OPENAI_CHAT_MAX_TOKENS,
                stream=True,
            )
            response = st.write_stream(output)


            #outputå†…ã«[]å½¢å¼ãŒã‚ã‚‹å ´åˆã¯ã€[]å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—ã—ã€sourcetempå†…ã®filenameã¨ä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’æ¢ç´¢ã™ã‚‹
            #ä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°ã€sourcetempå†…ã®å†…å®¹ã‚’è¡¨ç¤ºã™ã‚‹ã€‚æ—¢ã«1å›è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€2å›ç›®ä»¥é™ã¯è¡¨ç¤ºã—ãªã„
            with st.expander("å‚ç…§å…ƒ"):
                displayed_files = []  # æ—¢ã«è¡¨ç¤ºã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿½è·¡ã™ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
                if "[" in response:
                    filename = re.findall(r'\[(.*?)\]', response)
                    for i in range(len(filename)):
                        for j in range(len(sourcetemp)):
                            if filename[i] in sourcetemp[j] and filename[i] not in displayed_files:  # ãƒ•ã‚¡ã‚¤ãƒ«åãŒæ—¢ã«è¡¨ç¤ºã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
                                with st.popover(filename[i]):
                                    st.write(sourcetemp[j])
                                displayed_files.append(filename[i])  # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¿½è·¡ãƒªã‚¹ãƒˆã«è¿½åŠ 
                else:
                    pass

        # Add ChatGPT response to conversation
        st.session_state.messages.append({"role": "assistant", "content": response})

        # idã«ã¯ãƒ©ãƒ³ãƒ€ãƒ å€¤ã‚’æŒ¿å…¥ã™ã‚‹
        id1 = randomname(20)
        id2 = randomname(20)
        id3 = randomname(20)
        id4 = randomname(20)
        

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ Cosmos DB ã«ä¿å­˜ã™ã‚‹ã€‚
        add_to_cosmos({"id": id1, "session": st.session_state['session_id'], "role": "user", "content": user_input})
        add_to_cosmos({"id": id2, "session": st.session_state['session_id'], "role": "assistant", "content": response})
        add_to_cosmos({"id": id3, "session": st.session_state['session_id'], "role": "context", "content": prompt_source}) 
        add_to_cosmos({"id": id4, "session": st.session_state['session_id'], "role": "eval", "question": user_input, "answer": response, "context": prompt_source, "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}) 
        
if __name__ == '__main__':
    main()
