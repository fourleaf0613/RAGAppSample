{"query": "Pythonとは何ですか？", "ground_truth": "Pythonは、高水準で汎用的なプログラミング言語で、読みやすさとシンプルな構文が特徴です。ウェブ開発、データ分析、機械学習など様々な分野で広く使用されています。", "response": "Pythonは、プログラミング言語の一つであり、特に人工知能（AI）やディープラーニングの分野で広く使用されています。Pythonはそのシンプルで読みやすい文法と豊富なライブラリが特徴で、初心者からプロフェッショナルまで幅広いユーザーに支持されています。\n\n具体的には、Pythonは以下のような特徴を持っています：\n\n- **シンプルで読みやすい文法**：Pythonのコードは他の多くのプログラミング言語に比べて直感的で読みやすいです。\n- **豊富なライブラリ**：Pythonには、データ解析、機械学習、ウェブ開発など様々な分野で利用できるライブラリが豊富に揃っています。\n- **クロスプラットフォーム**：PythonはWindows、macOS、Linuxなど様々なプラットフォームで動作します。\n\n特にAIやディープラーニングの分野では、TensorFlowやPyTorchといったディープラーニングライブラリがPythonで提供されており、これらのライブラリを使って高度な機械学習モデルを構築することができます。\n\n[20230217_AIの進化と日本の戦略_松尾研.pdf]", "context": "## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## Logical Inference\n\nInput: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods !\n\nModel Output: TPUs are a type of computer chip that Google uses for deep learning. A \"pod\" is a group of TPUs. A \"pod\" is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs .\n\nInput: Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. Going home next Tuesday!\n\nQuestion: Is it likely that Shelley will be near the Pacific Ocean this weekend? Model Output: The city with the famous market where they throw the fish is Seattle, Washington. Seattle is on the Pacific Ocean. Shelley is visiting Seattle, so she will be near the Pacific Ocean this weekend. The answer is \"yes\", it is likely that Shelley will be near the Pacific Ocean this weekend.\n\n\n\n<!-- PageNumber=\"13\" -->\n\n大規模言語モデル (Large Language Models; LLMs) より大きなモデルに\n===\n\n<figure>\n\n![](figures/12)\n\n<!-- FigureContent=\"GPT-4 (?)\n\nNumber of parameters\n\n(In Billion)\n\nM\n 10,000.00 Switch Transformer (1571B) 1,000.00 悟空2.0(1750B) :unselected: 100.00 GPT-3(175B) PaLM (540B) 10.00 Turning-NLG(17.2B) Megatron-LM (8.3B) 1.00 GPT-2(1.5B) 0.10 BERT-L (340M) ELMo(94M) 0.01 2018 2019 2020 2021 2022 2023\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"14\" -->\n\n\n\n\n\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n\n·ChatGPTの出現とその活用方法/影響\n\n·今後の社会/仕事への影響、日本の戦略\n\n\n\n<!-- PageNumber=\"15\" -->\n:unselected: :unselected:\nChatGPT\n===\n\n\n\nOpen AIは2022年11月30日にChatGPTを公開。 現在は無料公開中で、公開から1週間で100万ユーザ、2ヶ月で1億ユーザに到達。 その性能の高さから各所で話題に。 従来の大規模言語モデルよりも高度な意味理解と会話(チャット)が可能。 GPT-3 (とその後継のGPT-3.5) をベースにしている。\n\n<figure>\n\n![](figures/13)\n\n</figure>\n\n\n|||\n| - | - |\n| YU | 日本全体にイノベーションをもたらすにはどうすればいいですか? |\n| | 日本におけるイノベーションを促進するためには、政府がより効果的な政策を推進し、起業 家やビジネスに対する支援を強化することが重要です。また、教育システムを改革して、創 造的思考や問題解決の能力を高めることも必要です。さらに、企業が研究開発に投資する ことを奨励することも有益です。 |\n\n\n\n\n\n\n\n<!-- PageNumber=\"16\" -->\n\n\n\nオープンイノベーションについての会話例\n===\n\n| Reset Thread | YU | スタートアップによるオープンイノベーションについてどう思いますか? ||| |||\n| - | - | - | - |\n| \n| & Dark Mode (3) OpenAl Discord | | スタートアップによるオープンイノベーションは、新しいアイデアや技術を生み出すことに よって社会をより良いものにするための活動です。これは、企業や個人が独自の発明や技 | |\n| Learn More | | 術を公開し、他の人がそれを改善したり拡張したりすることで、技術や産業全体が向上す るというものです。私は、このような取り組みが、社会の発展と成長を促進するために非 常に重要な役割を果たすと考えています。 ||\n| [→ Log out ||||\n| | YU | スタートアップと大企業はどのような関係であるべきですか? | 了 |\n|| | スタートアップと大企業は、相互に補完的な関係にあるべきです。スタートアップは、新し 白 ワ いアイデアや技術を生み出すことで、産業や技術の発展を促進する役割を担っています。– 方で、大企業は、その規模や資金力を活かして、スタートアップが生み出したアイデアや技 術を拡大して普及させることができます。このような相互の協力関係は、産業の発展とイノ ベーションを促進するために非常に重要なものです。 ||\n|| YU | 大企業が具体的に何をしたら良いか教えてもらえますか? \n|| || | 大企業がスタートアップと協力するためには、様々な取り組みがあります。たとえば、大企 業は、スタートアップが生み出したアイデアや技術を採用することで、そのアイデアや技術 を拡大して普及させることができます。また、大企業は、スタートアップを投資すること で、その成長を支援することもできます。さらに、大企業は、スタートアップとの協力を通 じて、新しいビジネスモデルやサービスを開発することで、市場に新しい価値を提供するこ とができます。そのためには、大企業は、スタートアップとの接点を持つ担当者や部署を設 けるなどして、スタートアップとの協力を図る必要があります。 ||\n\n\n\n<!-- PageNumber=\"17\" -->\n\n\n\nChatGPTの学習方法\n\n\n## ChatGPTの学習は以下の3つのステップで構成されている\n\n\n## Step 1:教師あり学習\n\n·プロンプトとそれに対する適切な回答の ペアをアノテーター(人間) が考案 し、データセットを作成する\n\n·このデータセットを用いてGPT-3.5モデ ルをファインチューニングする\n\n<figure>\n\n![](figures/14)\n\n<!-- FigureContent=\"プロンプト:日本の SFT 首都は? 回答:東京です 0 . 自目目 . . データセット GPT-3.5モデル\" -->\n\n</figure>\n\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## ChatGPT\n\n• InstructGPTという先行モデルで用いられた「人間のフィードバ ックに基づいた強化学習」の考え方をChatGPTでも採用\n\n■ 文の良さを評価してくれる報酬モデルを新たに学習させて、 報酬が最大化するように強化学習を実施する\n\n\\- 有害なテキストを生成しないようにモデルを微調整\n\n· 会話データを用いてモデルのファインチューニングを行う\n\n■ アノテーターが擬似的な「ユーザーと AIの会話」のデータを 作成し、学習に活用\n\n\\- 会話ならではの砕けた表現などでも正しく意味理解し、 適切な回答の生成が可能\n\n\n\n\n\n<!-- PageNumber=\"19\" -->\n\n\n:unselected:\nChatGPTができること」自然言語におけるユースケース\n===\n\nM\n\n自然言語\n\nユースケース\n\nオリジナルが 人間のアウトプット\n\n<figure>\n\n![](figures/17)\n\n</figure>\n\n\nオリジナルが AIのアウトプット\n\n| 文章の 添削、校正 | 文法ミスだけでなく 内容の改善点まで 指摘 || | |\n| - | - | - | - | - |\n| 文章や 概念の要約 | 文字数を指定して 要約 || | |\n| 壁打ち、 ブレインストーミング | 「 \\~\\~ 」という考えの うち抜けている点を 指摘 || AIと人間で会話しな がらアイディエーション | |\n| リサーチ、 論点の洗い出し | | 「XX」について要点 だけ説明 | ディベート風に論点 を洗い出し | 表形式で比較表を 作成 |\n| アイデアの提案 | | SEO対策したタイト ルやキーワード形成 | 広告文の自動生成 | 何かに なりきって答える |\n||\n||| | | || 結婚式のスピーチの アウトライン作成 | 人気の出るブログの 内容案の提案 | 例題や乱数などの 生成 |\n||| … | … | … |\n\n従来と同じタスクだが、 精度が大幅に向上\n\nChatGPTの卓越したコ ミュニケーション精度と 圧倒的な知識量(デー 夕量,パラメータ数)か ら、以前では決してでき なかったことまでできる ようになっている。\n\n\n\n\n\n<!-- PageNumber=\"20\" -->\n\nChatGPTへの対応\n===\n\n海外では既に学校や学会でChatGPTの使い方に対して対応\n\nM\n\n• ニューヨーク、シアトル州の公立学校においてChatGPTの宿題への利用を禁止\n\n● 一方で一部の教育機関では、ChatGPTを教育のツールとして積極的に活用しようとする動き 例えば、英語学習において、ChatGPTを使って文章を作成する練習をすることで、自然な英語表 現を身につけることができる\n\n<figure>\n\n![](figures/18)\n\n<!-- FigureContent=\"学校\" -->\n\n</figure>\n\n\n\\- I\n\nI\n\n科学論文\n\n● ChatGPTを活用して科学論文を執筆することを禁止にするとICMLなどが発表\n\n● 一方で文章の編集や推敲に活用することは問題ないとされている\n\n\n\n<!-- PageNumber=\"21\" -->\n\n学校でのChatGPTの利用について\n\nM\n\neuronews.next\n\nBIZTECH NEWS\n\nMONEY\n\nWORK MOBILITY\n\nHEALTH HOME\n\nOPINION\n\nSERIES √\n\nThe New york Times\n\nTHE SHIFT\n\nDon't Ban ChatGPT in Schools. Teach With It.\n\nOpenAl's new chatbot is raising fears of cheating on homework, but its potential as an educational tool outweighs its risks.\n\nRecently, I gave a talk to a group of K-12 teachers and public school administrators in New York. The topic was artificial intelligence, and how schools would need to adapt to prepare students for a future filled with all kinds of capable A.I. tools.\n\nBut it turned out that my audience cared about only one A.I. tool: ChatGPT, the buzzy chatbot developed by OpenAI that is capable of writing cogent essays, solving science and math problems and producing working computer code.\n\nChatGPT is new - it was released in late November - but it has already sent many educators into a panic. Students are using it to write their assignments, passing off A.I .- generated essays and problem sets as their own. Teachers and school administrators have been scrambling to catch students using the tool to cheat, and they are fretting about the havoc ChatGPT could wreak on their lesson plans. (Some publications have declared, perhaps a bit prematurely, that ChatGPT has killed homework altogether.)\n\nWORK\n\n\n## Students are using ChatGPT to do their homework. Should schools ban Al tools, or embrace them?\n\nBy Oceane Duboust & Camille Bello . Updated: 28/01/2023\n\nIs the end of homework near? As new powerful artificial intelligence (AI) tools like ChatGPT take the Internet by storm, teachers concerned with Al-driven cheating are questioning their teaching and assessment methods.\n\nChatGPT, the most powerful Al language model ever developed by the company OpenAl, is capable of generating natural-sounding text on demand, including in a specific style or in several languages, in just a few seconds.\n\nThe quality of the copy it produces is sufficient to impress teachers in secondary and higher education, and even researchers.\n\n\"Young or not, we are all amazed at how quickly and relevantly it responds,\" Cecile Cathelin, a teacher at a high school in the French city of Tours, told Euronews Next.\n\nRELATED ● ChatGPT: Why the human-like Al chatbot suddenly has everyone talking\n\nThe use of Al tools in copywriting has sparked an outcry around the world. In the United States, public schools in New York and Seattle have decided to block ChatGPT from their devices and\n\nWiFi networks\n\nhttps://www.euronews.com/hext/2023/01/28/students-are-using-chatgpt-to-do-their-homework-should-schools-ban-ai-tools-or-embrace-the https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html\n\n©MATSUO LAB, THE UNIVERSITY OF TOKYO\n\n<!-- PageNumber=\"22\" -->\n\nM\n\n\n\n\n## The Guardian\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## 日本の戦略\n\n\n\nChatGPTの出現により大きく仕事のやり方が変わる。AIの「新しい時代」に入った。\n\n多くの人が、この技術はすごいと理解し、世の中が変わると確信した。それによって、本当に変化が起こる。資金も人も流れ る。ChatGPTにより、新しい時代に入ることが確定した。賽は投げられた。\n\nそのときに、日本としてどうすべきか。基本的には3つの戦略。新しい時代なので、やり方によっては(厳しい戦いだが) 勝 てるチャンスがあるということでもある。ただし、急ぐ必要がある。\n\n\n### 1\\. 大規模言語モデルを自ら開発する\n\n■ 数百億円あれば同じようなものは作れる(ただし、その間に相手はもっと先に行く。)\n\n\\- 今後のインパクトの大きさを考えれば、この戦いに参入するチケットとしては安い。この機会が開いているウィンドウは短い。\n\n\n## 2\\. APIを使いサービスを作ることを奨励する\n\n\\- ChatGPTなどのAPIを使って、ローカライズした専用アプリ、専用ソフトウェアが多く出現。国内の市場になるので、最低限ここはし :unselected: っかり伸ばすべき。\n\n\\- 一方Apple Store等と同じく、手数料を払い続けないといけない。\n\n\n## 3\\. ユーザとしての活用を促進する\n\n\\- DXが進んでいない現状において、言語による指示ができることは、DXの決め手になる可能性はある\n\n■ つまり、DXにおけるリープフロッグ。(アフリカに固定電話が入ってないのに携帯が入ったように。)\n\n\n\n<!-- PageNumber=\"30\" -->\n\nM\n\n<figure>\n\n![](figures/23)\n\n<!-- FigureContent=\"W 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\" -->\n\n</figure>\n\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ###M\nAIの進化と日本の戦略\nM 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\n23/2/17\nM\n<figure>\n![](figures/0)\n</figure>\n1993年 香川県立丸亀高校卒。 1997年 東京大学工学部電子情報工学科卒業 2002年 同大学院博士課程修了. 博士(工学)。 産業技術総合研究所 研究員 2005年 スタンフォード大学客員研究員 2007年 東京大学大学院工学系研究科 技術経営戦略学専攻 准教授 2014年 東京大学大学院工学系研究科 技術経営戦略学専攻 特任准教授 2019年 東京大学大学院工学系研究科 人工物工学研究センター/技術経営戦略学専攻 教授\n2017年\\~ 日本ディープラーニング協会 理事長 2019年\\~ ソフトバンクグループ株式会社 社外取締役、人工知能学会理事、情報処理学会理 デジタル市場競争会議 構成員 2021年\\~ 新しい資本主義実現会議 有識者構成員\n<!-- PageNumber=\"2\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n·ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"3\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n● ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"4\" -->\n:unselected: :unselected:\nAIの歴史 (DBJインフラレポート(松尾研共著)より抜粋)\n===\n :selected:\n現在は、AIの歴史において、技術的進歩、マジンパワーの向上、データ量増大等を要因とする、第3次AIブームと位置付けられる\n===\n :selected:\nAIの歴史と第3次Alブーム\n<figure>\n![](figures/1)\n<!-- FigureContent=\"シンギュラ リティの恐怖 ワトソン お供電王戦 第3次AIブーム ティープ ラーニング 機械学習 冬の時代 冬の時代 ↓ 第2次 第1次 AIブーム ↓ Alブーム 1960年代 1970年代 1980年代 1990年代 2000年代 2010年代\" -->\n</figure>\n■ 第1次AIブームでは、特定の問題は解けたが、現実社会の複 雑な問題は解決できなかった\n■ 第2次AIブームでは、エキスパートシステムの導入により、Al が専門家の役割を担うことが可能になったが、コンピュータに 大量の知識を入力して管理するには、技術、費用、時間の限 界があり、汎用性を得られなかった\n■ 第3次AIブームでは、技術的なブレークスルーによりAIの実用 化が大きく進捗すると期待されている\n第3次AIブームを支える要因\n1ディーブラーニングの進化\nクマシンパワーの向上\n●データ量の増大\n<figure>\n![](figures/2)\n<!-- FigureContent=\"セタバーイトー エクサ メトーイトー テラバーイト ペタバーイトー\" -->\n</figure>\n2.2セタンペーパー\n全世界の企業が\n格納する情報量\n130エクサバイーイト\n世界のモバイル·データ\nのトラフィック量予測\n100ペタタバイーイトー\nFacebookユーザーの ゴンテンツ量 121テラノベーイト\n国内データ伝送量予測\n<!-- PageNumber=\"5\" -->\n<figure>\n![](figures/3)\n</figure>\nビントン教授\npython Pythonプログラミング言語\nTensorFlow PyTorch\nディーブラーニングライブラリ\nトロント大学·ヒントン教授によって ディーブラーニングの有効性実証\n■ Python言語が普及し、各社から ディーブラーニングのライブラリが リリース\n<figure>\n![](figures/4)\n<!-- FigureContent=\"GPU\" -->\n</figure>\n·GPUの普及や、クラウド上での計 算リソースの活用が進展\n·数十時間を要していたAIの計算時 間を、大幅に短縮\n■ 2010年⇒2020年010年間で、 データ量は40倍に増加すると試算\n■利用できるデジタルデータの増加 が、AIの発展に貢献\nM\nAIの中のディープラーニング (深層学習)\n===\n■ Al(人工知能)とは、知的なコンピュータブログラムを作る科学と技術である\n :unselected:\n■ AI技術の一つであるディーブラーニング(深層学習)とは、人間が自然に行うタスクをコンピュータに学習させる機械学習の手法の一つ :selected: である\nAIの三大分類\n<figure>\n![](figures/5)\n<!-- FigureContent=\"Al(人工知能) 人間と同様の知識を実現させようという取り組みやその技術 機械戒学習 特定のタスクャトレーニングにより実行できるようになるAl 人が特徴を定義 ディーブラーニング マゾンカ特徴を自動応義\" -->\n</figure>\nAl性能が飛躍的\nトし、 マーケティングの世界でも期待値が急増\n第3次AIブー/\n<!-- PageNumber=\"6\" -->\nM\nディープラーニングとは\n :selected:\n多層のニューラルネットワーク (NN)を用いた手法の総称\n :selected:\nそれぞれのユニット (ニューロン)が、重み和(重みをかけた合計を求める処理) の丸め) を行う\n\\+活性化関数 (0-1へ\n :selected:\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## ChatGPT\n\n• InstructGPTという先行モデルで用いられた「人間のフィードバ ックに基づいた強化学習」の考え方をChatGPTでも採用\n\n■ 文の良さを評価してくれる報酬モデルを新たに学習させて、 報酬が最大化するように強化学習を実施する\n\n\\- 有害なテキストを生成しないようにモデルを微調整\n\n· 会話データを用いてモデルのファインチューニングを行う\n\n■ アノテーターが擬似的な「ユーザーと AIの会話」のデータを 作成し、学習に活用\n\n\\- 会話ならではの砕けた表現などでも正しく意味理解し、 適切な回答の生成が可能\n\n\n\n\n\n<!-- PageNumber=\"19\" -->\n\n\n:unselected:\nChatGPTができること」自然言語におけるユースケース\n===\n\nM\n\n自然言語\n\nユースケース\n\nオリジナルが 人間のアウトプット\n\n<figure>\n\n![](figures/17)\n\n</figure>\n\n\nオリジナルが AIのアウトプット\n\n| 文章の 添削、校正 | 文法ミスだけでなく 内容の改善点まで 指摘 || | |\n| - | - | - | - | - |\n| 文章や 概念の要約 | 文字数を指定して 要約 || | |\n| 壁打ち、 ブレインストーミング | 「 \\~\\~ 」という考えの うち抜けている点を 指摘 || AIと人間で会話しな がらアイディエーション | |\n| リサーチ、 論点の洗い出し | | 「XX」について要点 だけ説明 | ディベート風に論点 を洗い出し | 表形式で比較表を 作成 |\n| アイデアの提案 | | SEO対策したタイト ルやキーワード形成 | 広告文の自動生成 | 何かに なりきって答える |\n||\n||| | | || 結婚式のスピーチの アウトライン作成 | 人気の出るブログの 内容案の提案 | 例題や乱数などの 生成 |\n||| … | … | … |\n\n従来と同じタスクだが、 精度が大幅に向上\n\nChatGPTの卓越したコ ミュニケーション精度と 圧倒的な知識量(デー 夕量,パラメータ数)か ら、以前では決してでき なかったことまでできる ようになっている。\n\n\n\n\n\n<!-- PageNumber=\"20\" -->\n\nChatGPTへの対応\n===\n\n海外では既に学校や学会でChatGPTの使い方に対して対応\n\nM\n\n• ニューヨーク、シアトル州の公立学校においてChatGPTの宿題への利用を禁止\n\n● 一方で一部の教育機関では、ChatGPTを教育のツールとして積極的に活用しようとする動き 例えば、英語学習において、ChatGPTを使って文章を作成する練習をすることで、自然な英語表 現を身につけることができる\n\n<figure>\n\n![](figures/18)\n\n<!-- FigureContent=\"学校\" -->\n\n</figure>\n\n\n\\- I\n\nI\n\n科学論文\n\n● ChatGPTを活用して科学論文を執筆することを禁止にするとICMLなどが発表\n\n● 一方で文章の編集や推敲に活用することは問題ないとされている\n\n\n\n<!-- PageNumber=\"21\" -->\n\n学校でのChatGPTの利用について\n\nM\n\neuronews.next\n\nBIZTECH NEWS\n\nMONEY\n\nWORK MOBILITY\n\nHEALTH HOME\n\nOPINION\n\nSERIES √\n\nThe New york Times\n\nTHE SHIFT\n\nDon't Ban ChatGPT in Schools. Teach With It.\n\nOpenAl's new chatbot is raising fears of cheating on homework, but its potential as an educational tool outweighs its risks.\n\nRecently, I gave a talk to a group of K-12 teachers and public school administrators in New York. The topic was artificial intelligence, and how schools would need to adapt to prepare students for a future filled with all kinds of capable A.I. tools.\n\nBut it turned out that my audience cared about only one A.I. tool: ChatGPT, the buzzy chatbot developed by OpenAI that is capable of writing cogent essays, solving science and math problems and producing working computer code.\n\nChatGPT is new - it was released in late November - but it has already sent many educators into a panic. Students are using it to write their assignments, passing off A.I .- generated essays and problem sets as their own. Teachers and school administrators have been scrambling to catch students using the tool to cheat, and they are fretting about the havoc ChatGPT could wreak on their lesson plans. (Some publications have declared, perhaps a bit prematurely, that ChatGPT has killed homework altogether.)\n\nWORK\n\n\n## Students are using ChatGPT to do their homework. Should schools ban Al tools, or embrace them?\n\nBy Oceane Duboust & Camille Bello . Updated: 28/01/2023\n\nIs the end of homework near? As new powerful artificial intelligence (AI) tools like ChatGPT take the Internet by storm, teachers concerned with Al-driven cheating are questioning their teaching and assessment methods.\n\nChatGPT, the most powerful Al language model ever developed by the company OpenAl, is capable of generating natural-sounding text on demand, including in a specific style or in several languages, in just a few seconds.\n\nThe quality of the copy it produces is sufficient to impress teachers in secondary and higher education, and even researchers.\n\n\"Young or not, we are all amazed at how quickly and relevantly it responds,\" Cecile Cathelin, a teacher at a high school in the French city of Tours, told Euronews Next.\n\nRELATED ● ChatGPT: Why the human-like Al chatbot suddenly has everyone talking\n\nThe use of Al tools in copywriting has sparked an outcry around the world. In the United States, public schools in New York and Seattle have decided to block ChatGPT from their devices and\n\nWiFi networks\n\nhttps://www.euronews.com/hext/2023/01/28/students-are-using-chatgpt-to-do-their-homework-should-schools-ban-ai-tools-or-embrace-the https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html\n\n©MATSUO LAB, THE UNIVERSITY OF TOKYO\n\n<!-- PageNumber=\"22\" -->\n\nM\n\n\n\n\n## The Guardian\n\n\n\n\n"}
{"query": "Azure Cognitive Searchの主な機能は何ですか？", "ground_truth": "Azure Cognitive Searchは、フルテキスト検索、フィルタリング、ファセットナビゲーション、シノニムマッピング、自然言語処理などの機能を提供するクラウドベースの検索サービスです。", "response": "申し訳ありませんが、提供された情報源にはAzure Cognitive Searchの主な機能に関する情報が含まれていません。そのため、正確な回答を提供することができません。", "context": "## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## マイクロソフト、OpenAlの言語モデルを搭載 した「Bing」を発表\n\nMicrosoftは米国時間2月7日、「ChatGPT」を支える技術を搭載した検索エンジン 「Bing」の新しいバージョンを発表した。ChatGPTは、会話型で創造的な回答を返す人 工知能(AI) システムで、検索分野を長年にわたって独占するGoogleを追い抜く、初め ての大きなチャンスをもたらしている。\n\n<figure>\n\n![](figures/21)\n\n<!-- FigureContent=\". I Mienmat Sing 4 5 . LOLDOC\n提供:Stephen Shankland/CNET\" -->\n\n</figure>\n\n\nBingは新たに、Microsoftが提携しているOpenAlの大規模言語モデルによる情報を注 入した検索結果を提示するようになり、「ウェブに対するAIコパイロット」になったと同 社は述べた。Bingには、新しいチャットウィンドウも表示されて、Microsoftによると、 そこで、面接の準備やトリビアクイズの作成を手伝ってもらったり、買い物や旅行のアド バイスを受けたりできるという。この技術は、同社の「Edge」ブラウザーにも組み込ま れており、PDFのレポート内容を要約したり、「LinkedIn」の投稿を作成したりといっ たタスクを実行できる。\n\nGoogleが会話型AIサービス「Bard」発表、まずはテストユー ザーに公開\n\nL 2023年02月07日 18時44分 公開\n\n[エースラッシュ, ITmedia]\n\n<figure>\n\n![](figures/22)\n\n<!-- FigureContent=\"印刷 25 f Share B! 1 :selected: >\" -->\n\n</figure>\n\n\n米Googleは、2月7日に対話アプリ用言語モデル「LaMDA (Language Model for Dialogue Applications) 」を活用した実験的な会話型AIサービス「Bard」を発表した。 今後の一般公開に先立ち、まずは「信頼できるテストユーザー」にのみ公開するとして いる。\n\nBardは幅広い知識と大規模言語モデルの能力、知性、創造性を組み合わせることを目 指し、Webからの情報を活用して最新かつ質の高い応答を提供。例として「NASAのジ ェームズ·ウェッブ宇宙望遠鏡による新発見を9歳の子供に説明すること」や「サッカ 一界のトップストライカーについて学ぶこと」などが可能になるという。\n\nより多くのユーザーへの提供と多くのフィードバックを得るため、必要な計算力が大 幅に少ない軽量バージョンのLaMDAを公開。外部からのフィードバックと内部テストを 組み合わせてBardの回答が品質、安全性、現実世界の情報の根拠の高い基準(英語)を 満たしていることを確認するという。\n\nさらに同社はLaMDA、PaLM、Imagen、MusicLMなど最新のAIテクノロジーを Google製品に取り入れることを目指し、まずは検索での活用に取り組む。例えば、こ れまでGoogle検索では「ピアノの鍵盤の数は?」といった事実に基づいた迅速な回答が 求められていたが「ピアノとギターのどちらが習得しやすいか」「それぞれどのくらい の練習が必要か」など、より深い洞察と理解を得る検索が増えてきている。\n\nhttps://japan.cnet.com/article/35199718/\n\n\n\n<!-- PageNumber=\"28\" -->\n:selected:\nM\n\nChatGPTなどの大規模言語モデルの可能性\n===\n\n既存ツールの使われ方に大きな変化が生まれ、かつこれまでには不可能だった専門的な業務を代行できるツールが多く誕 生する見込み。これまでのホワイトカラーの仕事ほぼ全てに影響が出る可能性が高い\n\n既存ツールの変化\n\n目的に特化したChatGPTの出現\n\n\n## · 検索がなくなる可能性がある。\n\n· 質問しても「このページを自分で読んで」と返してくるぶっきらぼう な人間 vs 答えをちゃんと教えてくれる人間、どちらがいいか?\n\n\\- 世界トップクラスの時価総額(1.44兆ドル、2023/2時点) の 会社の主力事業がなくなるかもしれないということ。\n\n\n### ·Office製品は全部変わる (Word, Excel, Powerpoint)\n\n\\- 先述したリサーチの事例のように人間が自分で打つ時代は終わ る。仕事の仕方は大幅に変わる\n\n\\- 情報の収集、要約、可視化まで自動化されていく可能性\n\n攻撃的な会話、偏った意見、予想や予測等はしないように、 強化学習で訓練。逆に言うと\n\n\n### 「目的に特化した」学習をさせれば、専用のGhatGPTが作れる\n\n·法律的な見地から正しいコメントをする\n\n· 会計的な見地から正しいコメントをする\n\n· 医学的な見地から正しいコメントをする\n\n· 相手をはげましたり、なぐさめたり、元気づける\n\n● 相手の理解の程度にあわせて、分かりやすく教えてくれる\n\n· 相手の要望を聞き出し、目的の商品を薦める\n\n·複数の人の希望を聞き出し、うまく妥協点を調整する…\n\n\n\n\n\n<!-- PageNumber=\"29\" -->\n:selected:\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## マイクロソフト、OpenAlの言語モデルを搭載 した「Bing」を発表\n\nMicrosoftは米国時間2月7日、「ChatGPT」を支える技術を搭載した検索エンジン 「Bing」の新しいバージョンを発表した。ChatGPTは、会話型で創造的な回答を返す人 工知能(AI) システムで、検索分野を長年にわたって独占するGoogleを追い抜く、初め ての大きなチャンスをもたらしている。\n\n<figure>\n\n![](figures/21)\n\n<!-- FigureContent=\". I Mienmat Sing 4 5 . LOLDOC\n提供:Stephen Shankland/CNET\" -->\n\n</figure>\n\n\nBingは新たに、Microsoftが提携しているOpenAlの大規模言語モデルによる情報を注 入した検索結果を提示するようになり、「ウェブに対するAIコパイロット」になったと同 社は述べた。Bingには、新しいチャットウィンドウも表示されて、Microsoftによると、 そこで、面接の準備やトリビアクイズの作成を手伝ってもらったり、買い物や旅行のアド バイスを受けたりできるという。この技術は、同社の「Edge」ブラウザーにも組み込ま れており、PDFのレポート内容を要約したり、「LinkedIn」の投稿を作成したりといっ たタスクを実行できる。\n\nGoogleが会話型AIサービス「Bard」発表、まずはテストユー ザーに公開\n\nL 2023年02月07日 18時44分 公開\n\n[エースラッシュ, ITmedia]\n\n<figure>\n\n![](figures/22)\n\n<!-- FigureContent=\"印刷 25 f Share B! 1 :selected: >\" -->\n\n</figure>\n\n\n米Googleは、2月7日に対話アプリ用言語モデル「LaMDA (Language Model for Dialogue Applications) 」を活用した実験的な会話型AIサービス「Bard」を発表した。 今後の一般公開に先立ち、まずは「信頼できるテストユーザー」にのみ公開するとして いる。\n\nBardは幅広い知識と大規模言語モデルの能力、知性、創造性を組み合わせることを目 指し、Webからの情報を活用して最新かつ質の高い応答を提供。例として「NASAのジ ェームズ·ウェッブ宇宙望遠鏡による新発見を9歳の子供に説明すること」や「サッカ 一界のトップストライカーについて学ぶこと」などが可能になるという。\n\nより多くのユーザーへの提供と多くのフィードバックを得るため、必要な計算力が大 幅に少ない軽量バージョンのLaMDAを公開。外部からのフィードバックと内部テストを 組み合わせてBardの回答が品質、安全性、現実世界の情報の根拠の高い基準(英語)を 満たしていることを確認するという。\n\nさらに同社はLaMDA、PaLM、Imagen、MusicLMなど最新のAIテクノロジーを Google製品に取り入れることを目指し、まずは検索での活用に取り組む。例えば、こ れまでGoogle検索では「ピアノの鍵盤の数は?」といった事実に基づいた迅速な回答が 求められていたが「ピアノとギターのどちらが習得しやすいか」「それぞれどのくらい の練習が必要か」など、より深い洞察と理解を得る検索が増えてきている。\n\nhttps://japan.cnet.com/article/35199718/\n\n\n\n<!-- PageNumber=\"28\" -->\n:selected:\nM\n\nChatGPTなどの大規模言語モデルの可能性\n===\n\n既存ツールの使われ方に大きな変化が生まれ、かつこれまでには不可能だった専門的な業務を代行できるツールが多く誕 生する見込み。これまでのホワイトカラーの仕事ほぼ全てに影響が出る可能性が高い\n\n既存ツールの変化\n\n目的に特化したChatGPTの出現\n\n\n## · 検索がなくなる可能性がある。\n\n· 質問しても「このページを自分で読んで」と返してくるぶっきらぼう な人間 vs 答えをちゃんと教えてくれる人間、どちらがいいか?\n\n\\- 世界トップクラスの時価総額(1.44兆ドル、2023/2時点) の 会社の主力事業がなくなるかもしれないということ。\n\n\n### ·Office製品は全部変わる (Word, Excel, Powerpoint)\n\n\\- 先述したリサーチの事例のように人間が自分で打つ時代は終わ る。仕事の仕方は大幅に変わる\n\n\\- 情報の収集、要約、可視化まで自動化されていく可能性\n\n攻撃的な会話、偏った意見、予想や予測等はしないように、 強化学習で訓練。逆に言うと\n\n\n### 「目的に特化した」学習をさせれば、専用のGhatGPTが作れる\n\n·法律的な見地から正しいコメントをする\n\n· 会計的な見地から正しいコメントをする\n\n· 医学的な見地から正しいコメントをする\n\n· 相手をはげましたり、なぐさめたり、元気づける\n\n● 相手の理解の程度にあわせて、分かりやすく教えてくれる\n\n· 相手の要望を聞き出し、目的の商品を薦める\n\n·複数の人の希望を聞き出し、うまく妥協点を調整する…\n\n\n\n\n\n<!-- PageNumber=\"29\" -->\n:selected:\n\n\n## filename: test111.txt\n\n ## context 1. RAGシステム構築に興味を持っている​\n\nセッション:「Azure OpenAI Service と RAG について(基本)」のセッション(座学)を実施する​\n\n情報共有: 実装方法が分からない場合は以下を実施​\n\nMicrosoft Learnの関連ページの共有​\n\nGitHub レポジトリ(Solution Accelerator)の紹介​\n\nハンズオントレーニングの実施​\n\n2. RAGシステムを構築し始めている (困ってはない)​\n\nセッション:「RAGの精度向上のためのチューニングポイント」のセッション(座学)を実施する​\n\n3. RAGシステムを構築したが回答精度が悪くて困っている​\n\nヒアリング: 困っている点についてのヒアリングを実施する​\n\nセッション: 「RAGの精度向上のためのチューニングポイント」のセッション(座学)を提供する​\n\n技術Q&A: 困っている点についての技術Q&Aセッションを実施する​\n\nコワーク: 顧客からデータを共有してもらいSS/TSで手を動かして検証を行う(コワーク(Co-Work))​\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context 目的の動作を行うように、重みを調整する(誤差逆伝播)\n|+1層のユニットjの値:\nN\n<figure>\n![](figures/6)\n<!-- FigureContent=\"x1+1 = 0 .l+1 i=1 - 00000 :unselected: :unselected: :unselected: :unselected: :unselected: 00000 :unselected: :unselected: :unselected: :unselected: :unselected: :unselected: 0000 :unselected: :unselected: :unselected: :unselected: :unselected: - 入力 X :unselected: 出力 y -\" -->\n</figure>\n :unselected: :unselected: :unselected:\n<!-- PageNumber=\"7\" -->\n:selected:\nM\nディープラーニングによる自然言語処理が2018年ごろから急速に性能向上\n===\n2012年にDeep Learningが画像認識で大きなブレークスルー 2015年には画像·音声分野で人間を超える精度を達成\nGLUE (General Language Understanding Evaluation)\n| データセット | 概要 |\n| - | - |\n| CoLA | 正しい文法で書かれているかの二値分類 |\n| SST-2 | 映画レビューのpos/neg判定。文を構文末解析し、各フレー ズごとにpos/negが振られているが、GLUEでは文単位のもの のみを対象としている。 |\n| MRPC | 2文が同じ意味かどうかの二値分類 |\n| STS-B | 2文の類似度を1 -- 5で評価 |\n| QQP | 2つの質問文が同じ意味かどうかの二値分類 |\n| MNLI | 前提の文と仮説の文に対して、含意的/矛盾/無関係の3クラス 分類。 |\n| QNLI | SQUADの文章と質問のペアを、文章中の各文と質問のペアに し,その各文に質問の回答が含まれているかの二値分類を行 う。 |\n| RTE | 2文の含意の二値分類 |\n<figure>\n![](figures/7)\n</figure>\n自然言語処理 (NLP)では、2018年から急激に 精度が向上し、GLUE評価で人間の精度を超えた\nGLUE (NLPベンチマーク)の精度推移\n<figure>\n![](figures/8)\n<!-- FigureContent=\"90 人間:87.1 88.4 80 80.2 70 70 65.6 60 58.6 50 2013年 2017年以前 2018年3月 2018年10月 CBoW LSTM+Attn ELMo BERT XLNet T5\" -->\n</figure>\nわずか2年で約25%向上\n<!-- PageNumber=\"○○DO\" -->\n<!-- PageNumber=\"8\" -->\nM\n鍵となる技術:トランスフォーマー(L. Kaiser et al., 2017)\n===\n :selected:\n· 有名な「Attention is All You Need」論文。Googleの研究者ら。\n●「アテンション」という機構を大規模に使ったトランスフォーマーを提案。\nー アテンション(自己注意機構) : ニューラルネットワーク中のどこの情報をどのよ\nうに使うか自体を学習することができる。\nー トランスフォーマーは、マルチヘッドのセルフアテンションを多層に重ねたもの。\n\\- 多くのタスクでSOTA(最新性能)を出した。\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ###M\nAIの進化と日本の戦略\nM 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\n23/2/17\nM\n<figure>\n![](figures/0)\n</figure>\n1993年 香川県立丸亀高校卒。 1997年 東京大学工学部電子情報工学科卒業 2002年 同大学院博士課程修了. 博士(工学)。 産業技術総合研究所 研究員 2005年 スタンフォード大学客員研究員 2007年 東京大学大学院工学系研究科 技術経営戦略学専攻 准教授 2014年 東京大学大学院工学系研究科 技術経営戦略学専攻 特任准教授 2019年 東京大学大学院工学系研究科 人工物工学研究センター/技術経営戦略学専攻 教授\n2017年\\~ 日本ディープラーニング協会 理事長 2019年\\~ ソフトバンクグループ株式会社 社外取締役、人工知能学会理事、情報処理学会理 デジタル市場競争会議 構成員 2021年\\~ 新しい資本主義実現会議 有識者構成員\n<!-- PageNumber=\"2\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n·ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"3\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n● ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"4\" -->\n:unselected: :unselected:\nAIの歴史 (DBJインフラレポート(松尾研共著)より抜粋)\n===\n :selected:\n現在は、AIの歴史において、技術的進歩、マジンパワーの向上、データ量増大等を要因とする、第3次AIブームと位置付けられる\n===\n :selected:\nAIの歴史と第3次Alブーム\n<figure>\n![](figures/1)\n<!-- FigureContent=\"シンギュラ リティの恐怖 ワトソン お供電王戦 第3次AIブーム ティープ ラーニング 機械学習 冬の時代 冬の時代 ↓ 第2次 第1次 AIブーム ↓ Alブーム 1960年代 1970年代 1980年代 1990年代 2000年代 2010年代\" -->\n</figure>\n■ 第1次AIブームでは、特定の問題は解けたが、現実社会の複 雑な問題は解決できなかった\n■ 第2次AIブームでは、エキスパートシステムの導入により、Al が専門家の役割を担うことが可能になったが、コンピュータに 大量の知識を入力して管理するには、技術、費用、時間の限 界があり、汎用性を得られなかった\n■ 第3次AIブームでは、技術的なブレークスルーによりAIの実用 化が大きく進捗すると期待されている\n第3次AIブームを支える要因\n1ディーブラーニングの進化\nクマシンパワーの向上\n●データ量の増大\n<figure>\n![](figures/2)\n<!-- FigureContent=\"セタバーイトー エクサ メトーイトー テラバーイト ペタバーイトー\" -->\n</figure>\n2.2セタンペーパー\n全世界の企業が\n格納する情報量\n130エクサバイーイト\n世界のモバイル·データ\nのトラフィック量予測\n100ペタタバイーイトー\nFacebookユーザーの ゴンテンツ量 121テラノベーイト\n国内データ伝送量予測\n<!-- PageNumber=\"5\" -->\n<figure>\n![](figures/3)\n</figure>\nビントン教授\npython Pythonプログラミング言語\nTensorFlow PyTorch\nディーブラーニングライブラリ\nトロント大学·ヒントン教授によって ディーブラーニングの有効性実証\n■ Python言語が普及し、各社から ディーブラーニングのライブラリが リリース\n<figure>\n![](figures/4)\n<!-- FigureContent=\"GPU\" -->\n</figure>\n·GPUの普及や、クラウド上での計 算リソースの活用が進展\n·数十時間を要していたAIの計算時 間を、大幅に短縮\n■ 2010年⇒2020年010年間で、 データ量は40倍に増加すると試算\n■利用できるデジタルデータの増加 が、AIの発展に貢献\nM\nAIの中のディープラーニング (深層学習)\n===\n■ Al(人工知能)とは、知的なコンピュータブログラムを作る科学と技術である\n :unselected:\n■ AI技術の一つであるディーブラーニング(深層学習)とは、人間が自然に行うタスクをコンピュータに学習させる機械学習の手法の一つ :selected: である\nAIの三大分類\n<figure>\n![](figures/5)\n<!-- FigureContent=\"Al(人工知能) 人間と同様の知識を実現させようという取り組みやその技術 機械戒学習 特定のタスクャトレーニングにより実行できるようになるAl 人が特徴を定義 ディーブラーニング マゾンカ特徴を自動応義\" -->\n</figure>\nAl性能が飛躍的\nトし、 マーケティングの世界でも期待値が急増\n第3次AIブー/\n<!-- PageNumber=\"6\" -->\nM\nディープラーニングとは\n :selected:\n多層のニューラルネットワーク (NN)を用いた手法の総称\n :selected:\nそれぞれのユニット (ニューロン)が、重み和(重みをかけた合計を求める処理) の丸め) を行う\n\\+活性化関数 (0-1へ\n :selected:\n\n\n"}
{"query": "機械学習と深層学習の違いは何ですか？", "ground_truth": "機械学習は、データからパターンを学習して予測や分類を行う手法全般を指し、深層学習はその中でも多層のニューラルネットワークを用いて高度なパターン認識を行う技術です。深層学習は特に画像認識や自然言語処理で高い性能を発揮します。", "response": "機械学習と深層学習の違いについて説明します。\n\n機械学習（Machine Learning）は、特定のタスクを実行するためにデータから学習するアルゴリズムの総称です。機械学習では、特徴量（特徴）を人間が定義し、その特徴を基にモデルが学習を行います。例えば、画像認識のタスクでは、エッジ検出や色のヒストグラムなどの特徴を人間が設計し、それを基にモデルが学習します。\n\n一方、深層学習（Deep Learning）は、機械学習の一分野であり、多層のニューラルネットワーク（NN）を用いた手法の総称です。深層学習では、特徴量を自動的に学習することが可能です。つまり、人間が特徴を定義する必要がなく、モデル自体がデータから特徴を抽出し、学習を行います。これにより、より複雑なタスクや大規模なデータセットに対して高い性能を発揮することができます。\n\n具体的には、深層学習は以下のような特徴を持ちます：\n- 多層のニューラルネットワークを使用する\n- 重み和（重みをかけた合計を求める処理）と活性化関数を用いる\n- 誤差逆伝播法を用いて重みを調整する\n\nこれに対して、機械学習はより広範なアルゴリズムを含み、線形回帰、決定木、サポートベクターマシン（SVM）などが含まれます。\n\n[20230217_AIの進化と日本の戦略_松尾研.pdf]", "context": "## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ###M\nAIの進化と日本の戦略\nM 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\n23/2/17\nM\n<figure>\n![](figures/0)\n</figure>\n1993年 香川県立丸亀高校卒。 1997年 東京大学工学部電子情報工学科卒業 2002年 同大学院博士課程修了. 博士(工学)。 産業技術総合研究所 研究員 2005年 スタンフォード大学客員研究員 2007年 東京大学大学院工学系研究科 技術経営戦略学専攻 准教授 2014年 東京大学大学院工学系研究科 技術経営戦略学専攻 特任准教授 2019年 東京大学大学院工学系研究科 人工物工学研究センター/技術経営戦略学専攻 教授\n2017年\\~ 日本ディープラーニング協会 理事長 2019年\\~ ソフトバンクグループ株式会社 社外取締役、人工知能学会理事、情報処理学会理 デジタル市場競争会議 構成員 2021年\\~ 新しい資本主義実現会議 有識者構成員\n<!-- PageNumber=\"2\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n·ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"3\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n● ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"4\" -->\n:unselected: :unselected:\nAIの歴史 (DBJインフラレポート(松尾研共著)より抜粋)\n===\n :selected:\n現在は、AIの歴史において、技術的進歩、マジンパワーの向上、データ量増大等を要因とする、第3次AIブームと位置付けられる\n===\n :selected:\nAIの歴史と第3次Alブーム\n<figure>\n![](figures/1)\n<!-- FigureContent=\"シンギュラ リティの恐怖 ワトソン お供電王戦 第3次AIブーム ティープ ラーニング 機械学習 冬の時代 冬の時代 ↓ 第2次 第1次 AIブーム ↓ Alブーム 1960年代 1970年代 1980年代 1990年代 2000年代 2010年代\" -->\n</figure>\n■ 第1次AIブームでは、特定の問題は解けたが、現実社会の複 雑な問題は解決できなかった\n■ 第2次AIブームでは、エキスパートシステムの導入により、Al が専門家の役割を担うことが可能になったが、コンピュータに 大量の知識を入力して管理するには、技術、費用、時間の限 界があり、汎用性を得られなかった\n■ 第3次AIブームでは、技術的なブレークスルーによりAIの実用 化が大きく進捗すると期待されている\n第3次AIブームを支える要因\n1ディーブラーニングの進化\nクマシンパワーの向上\n●データ量の増大\n<figure>\n![](figures/2)\n<!-- FigureContent=\"セタバーイトー エクサ メトーイトー テラバーイト ペタバーイトー\" -->\n</figure>\n2.2セタンペーパー\n全世界の企業が\n格納する情報量\n130エクサバイーイト\n世界のモバイル·データ\nのトラフィック量予測\n100ペタタバイーイトー\nFacebookユーザーの ゴンテンツ量 121テラノベーイト\n国内データ伝送量予測\n<!-- PageNumber=\"5\" -->\n<figure>\n![](figures/3)\n</figure>\nビントン教授\npython Pythonプログラミング言語\nTensorFlow PyTorch\nディーブラーニングライブラリ\nトロント大学·ヒントン教授によって ディーブラーニングの有効性実証\n■ Python言語が普及し、各社から ディーブラーニングのライブラリが リリース\n<figure>\n![](figures/4)\n<!-- FigureContent=\"GPU\" -->\n</figure>\n·GPUの普及や、クラウド上での計 算リソースの活用が進展\n·数十時間を要していたAIの計算時 間を、大幅に短縮\n■ 2010年⇒2020年010年間で、 データ量は40倍に増加すると試算\n■利用できるデジタルデータの増加 が、AIの発展に貢献\nM\nAIの中のディープラーニング (深層学習)\n===\n■ Al(人工知能)とは、知的なコンピュータブログラムを作る科学と技術である\n :unselected:\n■ AI技術の一つであるディーブラーニング(深層学習)とは、人間が自然に行うタスクをコンピュータに学習させる機械学習の手法の一つ :selected: である\nAIの三大分類\n<figure>\n![](figures/5)\n<!-- FigureContent=\"Al(人工知能) 人間と同様の知識を実現させようという取り組みやその技術 機械戒学習 特定のタスクャトレーニングにより実行できるようになるAl 人が特徴を定義 ディーブラーニング マゾンカ特徴を自動応義\" -->\n</figure>\nAl性能が飛躍的\nトし、 マーケティングの世界でも期待値が急増\n第3次AIブー/\n<!-- PageNumber=\"6\" -->\nM\nディープラーニングとは\n :selected:\n多層のニューラルネットワーク (NN)を用いた手法の総称\n :selected:\nそれぞれのユニット (ニューロン)が、重み和(重みをかけた合計を求める処理) の丸め) を行う\n\\+活性化関数 (0-1へ\n :selected:\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context 目的の動作を行うように、重みを調整する(誤差逆伝播)\n|+1層のユニットjの値:\nN\n<figure>\n![](figures/6)\n<!-- FigureContent=\"x1+1 = 0 .l+1 i=1 - 00000 :unselected: :unselected: :unselected: :unselected: :unselected: 00000 :unselected: :unselected: :unselected: :unselected: :unselected: :unselected: 0000 :unselected: :unselected: :unselected: :unselected: :unselected: - 入力 X :unselected: 出力 y -\" -->\n</figure>\n :unselected: :unselected: :unselected:\n<!-- PageNumber=\"7\" -->\n:selected:\nM\nディープラーニングによる自然言語処理が2018年ごろから急速に性能向上\n===\n2012年にDeep Learningが画像認識で大きなブレークスルー 2015年には画像·音声分野で人間を超える精度を達成\nGLUE (General Language Understanding Evaluation)\n| データセット | 概要 |\n| - | - |\n| CoLA | 正しい文法で書かれているかの二値分類 |\n| SST-2 | 映画レビューのpos/neg判定。文を構文末解析し、各フレー ズごとにpos/negが振られているが、GLUEでは文単位のもの のみを対象としている。 |\n| MRPC | 2文が同じ意味かどうかの二値分類 |\n| STS-B | 2文の類似度を1 -- 5で評価 |\n| QQP | 2つの質問文が同じ意味かどうかの二値分類 |\n| MNLI | 前提の文と仮説の文に対して、含意的/矛盾/無関係の3クラス 分類。 |\n| QNLI | SQUADの文章と質問のペアを、文章中の各文と質問のペアに し,その各文に質問の回答が含まれているかの二値分類を行 う。 |\n| RTE | 2文の含意の二値分類 |\n<figure>\n![](figures/7)\n</figure>\n自然言語処理 (NLP)では、2018年から急激に 精度が向上し、GLUE評価で人間の精度を超えた\nGLUE (NLPベンチマーク)の精度推移\n<figure>\n![](figures/8)\n<!-- FigureContent=\"90 人間:87.1 88.4 80 80.2 70 70 65.6 60 58.6 50 2013年 2017年以前 2018年3月 2018年10月 CBoW LSTM+Attn ELMo BERT XLNet T5\" -->\n</figure>\nわずか2年で約25%向上\n<!-- PageNumber=\"○○DO\" -->\n<!-- PageNumber=\"8\" -->\nM\n鍵となる技術:トランスフォーマー(L. Kaiser et al., 2017)\n===\n :selected:\n· 有名な「Attention is All You Need」論文。Googleの研究者ら。\n●「アテンション」という機構を大規模に使ったトランスフォーマーを提案。\nー アテンション(自己注意機構) : ニューラルネットワーク中のどこの情報をどのよ\nうに使うか自体を学習することができる。\nー トランスフォーマーは、マルチヘッドのセルフアテンションを多層に重ねたもの。\n\\- 多くのタスクでSOTA(最新性能)を出した。\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ###M\nAIの進化と日本の戦略\nM 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\n23/2/17\nM\n<figure>\n![](figures/0)\n</figure>\n1993年 香川県立丸亀高校卒。 1997年 東京大学工学部電子情報工学科卒業 2002年 同大学院博士課程修了. 博士(工学)。 産業技術総合研究所 研究員 2005年 スタンフォード大学客員研究員 2007年 東京大学大学院工学系研究科 技術経営戦略学専攻 准教授 2014年 東京大学大学院工学系研究科 技術経営戦略学専攻 特任准教授 2019年 東京大学大学院工学系研究科 人工物工学研究センター/技術経営戦略学専攻 教授\n2017年\\~ 日本ディープラーニング協会 理事長 2019年\\~ ソフトバンクグループ株式会社 社外取締役、人工知能学会理事、情報処理学会理 デジタル市場競争会議 構成員 2021年\\~ 新しい資本主義実現会議 有識者構成員\n<!-- PageNumber=\"2\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n·ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"3\" -->\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n● ChatGPTの出現とその活用方法/影響\n·今後の社会/仕事への影響、日本の戦略\n<!-- PageNumber=\"4\" -->\n:unselected: :unselected:\nAIの歴史 (DBJインフラレポート(松尾研共著)より抜粋)\n===\n :selected:\n現在は、AIの歴史において、技術的進歩、マジンパワーの向上、データ量増大等を要因とする、第3次AIブームと位置付けられる\n===\n :selected:\nAIの歴史と第3次Alブーム\n<figure>\n![](figures/1)\n<!-- FigureContent=\"シンギュラ リティの恐怖 ワトソン お供電王戦 第3次AIブーム ティープ ラーニング 機械学習 冬の時代 冬の時代 ↓ 第2次 第1次 AIブーム ↓ Alブーム 1960年代 1970年代 1980年代 1990年代 2000年代 2010年代\" -->\n</figure>\n■ 第1次AIブームでは、特定の問題は解けたが、現実社会の複 雑な問題は解決できなかった\n■ 第2次AIブームでは、エキスパートシステムの導入により、Al が専門家の役割を担うことが可能になったが、コンピュータに 大量の知識を入力して管理するには、技術、費用、時間の限 界があり、汎用性を得られなかった\n■ 第3次AIブームでは、技術的なブレークスルーによりAIの実用 化が大きく進捗すると期待されている\n第3次AIブームを支える要因\n1ディーブラーニングの進化\nクマシンパワーの向上\n●データ量の増大\n<figure>\n![](figures/2)\n<!-- FigureContent=\"セタバーイトー エクサ メトーイトー テラバーイト ペタバーイトー\" -->\n</figure>\n2.2セタンペーパー\n全世界の企業が\n格納する情報量\n130エクサバイーイト\n世界のモバイル·データ\nのトラフィック量予測\n100ペタタバイーイトー\nFacebookユーザーの ゴンテンツ量 121テラノベーイト\n国内データ伝送量予測\n<!-- PageNumber=\"5\" -->\n<figure>\n![](figures/3)\n</figure>\nビントン教授\npython Pythonプログラミング言語\nTensorFlow PyTorch\nディーブラーニングライブラリ\nトロント大学·ヒントン教授によって ディーブラーニングの有効性実証\n■ Python言語が普及し、各社から ディーブラーニングのライブラリが リリース\n<figure>\n![](figures/4)\n<!-- FigureContent=\"GPU\" -->\n</figure>\n·GPUの普及や、クラウド上での計 算リソースの活用が進展\n·数十時間を要していたAIの計算時 間を、大幅に短縮\n■ 2010年⇒2020年010年間で、 データ量は40倍に増加すると試算\n■利用できるデジタルデータの増加 が、AIの発展に貢献\nM\nAIの中のディープラーニング (深層学習)\n===\n■ Al(人工知能)とは、知的なコンピュータブログラムを作る科学と技術である\n :unselected:\n■ AI技術の一つであるディーブラーニング(深層学習)とは、人間が自然に行うタスクをコンピュータに学習させる機械学習の手法の一つ :selected: である\nAIの三大分類\n<figure>\n![](figures/5)\n<!-- FigureContent=\"Al(人工知能) 人間と同様の知識を実現させようという取り組みやその技術 機械戒学習 特定のタスクャトレーニングにより実行できるようになるAl 人が特徴を定義 ディーブラーニング マゾンカ特徴を自動応義\" -->\n</figure>\nAl性能が飛躍的\nトし、 マーケティングの世界でも期待値が急増\n第3次AIブー/\n<!-- PageNumber=\"6\" -->\nM\nディープラーニングとは\n :selected:\n多層のニューラルネットワーク (NN)を用いた手法の総称\n :selected:\nそれぞれのユニット (ニューロン)が、重み和(重みをかけた合計を求める処理) の丸め) を行う\n\\+活性化関数 (0-1へ\n :selected:\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## Logical Inference\n\nInput: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods !\n\nModel Output: TPUs are a type of computer chip that Google uses for deep learning. A \"pod\" is a group of TPUs. A \"pod\" is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs .\n\nInput: Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. Going home next Tuesday!\n\nQuestion: Is it likely that Shelley will be near the Pacific Ocean this weekend? Model Output: The city with the famous market where they throw the fish is Seattle, Washington. Seattle is on the Pacific Ocean. Shelley is visiting Seattle, so she will be near the Pacific Ocean this weekend. The answer is \"yes\", it is likely that Shelley will be near the Pacific Ocean this weekend.\n\n\n\n<!-- PageNumber=\"13\" -->\n\n大規模言語モデル (Large Language Models; LLMs) より大きなモデルに\n===\n\n<figure>\n\n![](figures/12)\n\n<!-- FigureContent=\"GPT-4 (?)\n\nNumber of parameters\n\n(In Billion)\n\nM\n 10,000.00 Switch Transformer (1571B) 1,000.00 悟空2.0(1750B) :unselected: 100.00 GPT-3(175B) PaLM (540B) 10.00 Turning-NLG(17.2B) Megatron-LM (8.3B) 1.00 GPT-2(1.5B) 0.10 BERT-L (340M) ELMo(94M) 0.01 2018 2019 2020 2021 2022 2023\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"14\" -->\n\n\n\n\n\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n\n·ChatGPTの出現とその活用方法/影響\n\n·今後の社会/仕事への影響、日本の戦略\n\n\n\n<!-- PageNumber=\"15\" -->\n:unselected: :unselected:\nChatGPT\n===\n\n\n\nOpen AIは2022年11月30日にChatGPTを公開。 現在は無料公開中で、公開から1週間で100万ユーザ、2ヶ月で1億ユーザに到達。 その性能の高さから各所で話題に。 従来の大規模言語モデルよりも高度な意味理解と会話(チャット)が可能。 GPT-3 (とその後継のGPT-3.5) をベースにしている。\n\n<figure>\n\n![](figures/13)\n\n</figure>\n\n\n|||\n| - | - |\n| YU | 日本全体にイノベーションをもたらすにはどうすればいいですか? |\n| | 日本におけるイノベーションを促進するためには、政府がより効果的な政策を推進し、起業 家やビジネスに対する支援を強化することが重要です。また、教育システムを改革して、創 造的思考や問題解決の能力を高めることも必要です。さらに、企業が研究開発に投資する ことを奨励することも有益です。 |\n\n\n\n\n\n\n\n<!-- PageNumber=\"16\" -->\n\n\n\nオープンイノベーションについての会話例\n===\n\n| Reset Thread | YU | スタートアップによるオープンイノベーションについてどう思いますか? ||| |||\n| - | - | - | - |\n| \n| & Dark Mode (3) OpenAl Discord | | スタートアップによるオープンイノベーションは、新しいアイデアや技術を生み出すことに よって社会をより良いものにするための活動です。これは、企業や個人が独自の発明や技 | |\n| Learn More | | 術を公開し、他の人がそれを改善したり拡張したりすることで、技術や産業全体が向上す るというものです。私は、このような取り組みが、社会の発展と成長を促進するために非 常に重要な役割を果たすと考えています。 ||\n| [→ Log out ||||\n| | YU | スタートアップと大企業はどのような関係であるべきですか? | 了 |\n|| | スタートアップと大企業は、相互に補完的な関係にあるべきです。スタートアップは、新し 白 ワ いアイデアや技術を生み出すことで、産業や技術の発展を促進する役割を担っています。– 方で、大企業は、その規模や資金力を活かして、スタートアップが生み出したアイデアや技 術を拡大して普及させることができます。このような相互の協力関係は、産業の発展とイノ ベーションを促進するために非常に重要なものです。 ||\n|| YU | 大企業が具体的に何をしたら良いか教えてもらえますか? \n|| || | 大企業がスタートアップと協力するためには、様々な取り組みがあります。たとえば、大企 業は、スタートアップが生み出したアイデアや技術を採用することで、そのアイデアや技術 を拡大して普及させることができます。また、大企業は、スタートアップを投資すること で、その成長を支援することもできます。さらに、大企業は、スタートアップとの協力を通 じて、新しいビジネスモデルやサービスを開発することで、市場に新しい価値を提供するこ とができます。そのためには、大企業は、スタートアップとの接点を持つ担当者や部署を設 けるなどして、スタートアップとの協力を図る必要があります。 ||\n\n\n\n<!-- PageNumber=\"17\" -->\n\n\n\nChatGPTの学習方法\n\n\n## ChatGPTの学習は以下の3つのステップで構成されている\n\n\n## Step 1:教師あり学習\n\n·プロンプトとそれに対する適切な回答の ペアをアノテーター(人間) が考案 し、データセットを作成する\n\n·このデータセットを用いてGPT-3.5モデ ルをファインチューニングする\n\n<figure>\n\n![](figures/14)\n\n<!-- FigureContent=\"プロンプト:日本の SFT 首都は? 回答:東京です 0 . 自目目 . . データセット GPT-3.5モデル\" -->\n\n</figure>\n\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context 目的の動作を行うように、重みを調整する(誤差逆伝播)\n|+1層のユニットjの値:\nN\n<figure>\n![](figures/6)\n<!-- FigureContent=\"x1+1 = 0 .l+1 i=1 - 00000 :unselected: :unselected: :unselected: :unselected: :unselected: 00000 :unselected: :unselected: :unselected: :unselected: :unselected: :unselected: 0000 :unselected: :unselected: :unselected: :unselected: :unselected: - 入力 X :unselected: 出力 y -\" -->\n</figure>\n :unselected: :unselected: :unselected:\n<!-- PageNumber=\"7\" -->\n:selected:\nM\nディープラーニングによる自然言語処理が2018年ごろから急速に性能向上\n===\n2012年にDeep Learningが画像認識で大きなブレークスルー 2015年には画像·音声分野で人間を超える精度を達成\nGLUE (General Language Understanding Evaluation)\n| データセット | 概要 |\n| - | - |\n| CoLA | 正しい文法で書かれているかの二値分類 |\n| SST-2 | 映画レビューのpos/neg判定。文を構文末解析し、各フレー ズごとにpos/negが振られているが、GLUEでは文単位のもの のみを対象としている。 |\n| MRPC | 2文が同じ意味かどうかの二値分類 |\n| STS-B | 2文の類似度を1 -- 5で評価 |\n| QQP | 2つの質問文が同じ意味かどうかの二値分類 |\n| MNLI | 前提の文と仮説の文に対して、含意的/矛盾/無関係の3クラス 分類。 |\n| QNLI | SQUADの文章と質問のペアを、文章中の各文と質問のペアに し,その各文に質問の回答が含まれているかの二値分類を行 う。 |\n| RTE | 2文の含意の二値分類 |\n<figure>\n![](figures/7)\n</figure>\n自然言語処理 (NLP)では、2018年から急激に 精度が向上し、GLUE評価で人間の精度を超えた\nGLUE (NLPベンチマーク)の精度推移\n<figure>\n![](figures/8)\n<!-- FigureContent=\"90 人間:87.1 88.4 80 80.2 70 70 65.6 60 58.6 50 2013年 2017年以前 2018年3月 2018年10月 CBoW LSTM+Attn ELMo BERT XLNet T5\" -->\n</figure>\nわずか2年で約25%向上\n<!-- PageNumber=\"○○DO\" -->\n<!-- PageNumber=\"8\" -->\nM\n鍵となる技術:トランスフォーマー(L. Kaiser et al., 2017)\n===\n :selected:\n· 有名な「Attention is All You Need」論文。Googleの研究者ら。\n●「アテンション」という機構を大規模に使ったトランスフォーマーを提案。\nー アテンション(自己注意機構) : ニューラルネットワーク中のどこの情報をどのよ\nうに使うか自体を学習することができる。\nー トランスフォーマーは、マルチヘッドのセルフアテンションを多層に重ねたもの。\n\\- 多くのタスクでSOTA(最新性能)を出した。\n\n\n"}
{"query": "社内でのリモートワークのメリットは何ですか？", "ground_truth": "リモートワークのメリットには、通勤時間の削減、柔軟な働き方によるワークライフバランスの向上、オフィススペースのコスト削減、地理的な制約を受けない人材採用の可能性などがあります。", "response": "申し訳ありませんが、提供された情報源には「社内でのリモートワークのメリット」についての具体的な記載がありません。そのため、この質問に対する回答を提供することができません。\n\n他にお手伝いできることがあれば教えてください。", "context": "## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## · 次の単語を予測するという、「自己教師あ り学習」で事前に学習する。\n\n· 事前学習をしておくことで、次に与えられる タスク(ダウンストリームタスク)で、少しの 例を与えるだけで学習することができる。\n\n<figure>\n\n![](figures/9)\n\n<!-- FigureContent=\"BERT (Ours) T, T2 … T. 4 Trm Trm : Trm Trm Trm Trm E, E2 EN …\" -->\n\n</figure>\n\n\n<figure>\n\n![](figures/10)\n\n<!-- FigureContent=\"Output Probabilities Softmax ↑ Linear Add & Norm Feed Forward Add & Norm Add & Norm Feed Multi-Head Attention Forward NX NX Add & Norm Add & Norm Masked Multi-Head Multi-Head Attention Attention Positional Positional Encoding :selected: Encoding Input Output Embedding Embedding ← Inputs Outputs (shifted right)\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"9\" -->\n:unselected:\n\n\nトランスフォーマの発明以降、次々と性能を上回るモデルが\n===\n\n| | BERT 2017 | ROBERT 2019 | DistilBERT 2019 | XLNet 2019 |\n| - | - | - | - | - |\n| Size (millions) | Base: 110 Large: 340 | Base: 110 Large: 340 | Base: 66 | Base: \\~ 110 Large: \\~ 340 |\n| Training Time | Base: 8 x V100 × 12 days\\* Large: 64 TPU Chips x 4 days (or 280 x V100 × 1 days\\*) | Large: 1024 x V100 × 1 day; 4-5 times more than BERT. | Base: 8 x V100 × 3.5 days; 4 times less than BERT. | Large: 512 TPU Chips x 2.5 days; 5 times more than BERT. |\n| Performance | Outperforms state-of- the-art in Oct 2018 | 2-20% improvement over BERT | 5% degradation from BERT | 2-15% improvement over BERT |\n| Data | 16 GB BERT data (Books Corpus + Wikipedia). 3.3 Billion words. | 160 GB (16 GB BERT data + 144 GB additional) | 16 GB BERT data. 3.3 Billion words. | Base: 16 GB BERT data Large: 113 GB (16 GB BERT data + 97 GB additional). 33 Billion words. |\n| Method | BERT (Bidirectional Transformer with MLM and NSP) | BERT without NSP | BERT Distillation | Bidirectional Transformer with Permutation based modeling |\n\n\n\n\n\n<!-- PageNumber=\"10\" -->\n\nGPT-3の登場\n\nM\n\nGPT-3とは:Open AIが2020年にリリースした高精度言語AI。1750億パラメータ。 自然言語処理のさまざまなタスクで驚くような性能を発揮した。英語圏や研究者らの間では2020年夏にかなり話題に。 OpenAlは、イーロン·マスク氏や、Y-Combinatorのサム·アルトマン氏らが2015年に非営利組織として設立(現在は営利も大)\n\n事例1:質問応答\n\n事例2:知識による補完\n\n事例3:文章生成\n\n受信メール:あなたのプロジェクトに1000万\n\n円の投資で十分でしょうか? (一部略)\n\n入力: \\* ありがとう\\*いいえ\n\n\\*最低金額は1500万円 \\*1500万円から受 付可能 \\*市場は9兆円\n\n自動生成:\n\nご連絡有難うございます。弊社にご興味をお 持ちいただき、誠に嬉しく存じます。 大変申し訳ございませんが、私共の最低投 資受付金額は1500万円となっております。 1000万円が十分な金額かどうかは現時点で は判断いたしかねますが、引き続き議論させ てください。なお、ご存じかもしれませんが、市 場規模はおよそ9兆円です。\n\nQ: どんな動物が好きですか? A: 私の好きな動物は犬です。 Q: なぜですか? A: 犬は忠実でフレンドリーだから です。\n\n| | A | B |\n| - | - | - |\n| 1 | State Name | Population |\n| 2 | Illinois | 12.67M |\n| 3 | California | 39.51M |\n| 4 | Ohio | 11.69M |\n| 5 | Michigan | =gpt3(A1:B4,A5) |\n\n自然な会話ができる。\n\n“10.31M”と自動入力\n\n最低限の入力で丁寧語で のメール文章を生成\n\n\n\n<!-- PageNumber=\"11\" -->\n\nM\n\nスケール則 (scaling law) :極めて重要な法則\n===\n :selected:\n• データを増やし、計算能力を増やし、パラメータの数(モデルの容量)を増やせば、精度がどんどん上がる。\n :selected:\n• つまり、大きければ大きいほど性能があがる。\n :selected:\n• GPT-3は、ウェブの大きなデータ(4兆単語)で事前学習。1750億パラメータ。学習に数億\\~数十億円のコスト。\n\n<figure>\n\n![](figures/11)\n\n<!-- FigureContent=\"7 4.2 6 L =(D/5.4 · 1013)-0.095 5.6 一 L = (N/8.8 · 1013)-0.076 3.9 5 4.8 Test Loss 3.6 4.0 4 3.3 3.2 3- 3.0 L =(Cmin/2.3· 108)-0.050 2.4 - 2 2.7 10-9 10-7 10-5 10-3 10-1 101 108 109 105 107 109 Compute Dataset Size Parameters PF-days, non-embedding tokens non-embedding\" -->\n\n<figcaption>\n\nFigure 1 Language modeling performance improves smoothly as we increase the model size, datasetset\nsize, and amount of compute2 used for training. For optimal performance all three factors must be scaled\nup in tandem. Empirical performance has a power-law relationship with each individual factor when not\nbottlenecked by the other two.\n\n</figcaption>\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"12\" -->\n\n## ビッグテックの大規模化への競争\n\nM\n\n• 2020.7 GPT-3 by OpenAl (1750億パラメータ)\n\n• 2021.12 Gopher by DeepMind (2800億パラメータ)\n\n• 2022.5 Open Pretrained Transformer (OPT) by Meta (1750億パラメータ)\n :selected:\n• 2022.4 Pathways Laguage Model (PaLM) by Google (5400億パラメータ)\n\n• 完全に規模の戦争に。冗談がなぜ面白いかを解説することもできる。\n\n\n## Explaining a Joke\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## · 次の単語を予測するという、「自己教師あ り学習」で事前に学習する。\n\n· 事前学習をしておくことで、次に与えられる タスク(ダウンストリームタスク)で、少しの 例を与えるだけで学習することができる。\n\n<figure>\n\n![](figures/9)\n\n<!-- FigureContent=\"BERT (Ours) T, T2 … T. 4 Trm Trm : Trm Trm Trm Trm E, E2 EN …\" -->\n\n</figure>\n\n\n<figure>\n\n![](figures/10)\n\n<!-- FigureContent=\"Output Probabilities Softmax ↑ Linear Add & Norm Feed Forward Add & Norm Add & Norm Feed Multi-Head Attention Forward NX NX Add & Norm Add & Norm Masked Multi-Head Multi-Head Attention Attention Positional Positional Encoding :selected: Encoding Input Output Embedding Embedding ← Inputs Outputs (shifted right)\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"9\" -->\n:unselected:\n\n\nトランスフォーマの発明以降、次々と性能を上回るモデルが\n===\n\n| | BERT 2017 | ROBERT 2019 | DistilBERT 2019 | XLNet 2019 |\n| - | - | - | - | - |\n| Size (millions) | Base: 110 Large: 340 | Base: 110 Large: 340 | Base: 66 | Base: \\~ 110 Large: \\~ 340 |\n| Training Time | Base: 8 x V100 × 12 days\\* Large: 64 TPU Chips x 4 days (or 280 x V100 × 1 days\\*) | Large: 1024 x V100 × 1 day; 4-5 times more than BERT. | Base: 8 x V100 × 3.5 days; 4 times less than BERT. | Large: 512 TPU Chips x 2.5 days; 5 times more than BERT. |\n| Performance | Outperforms state-of- the-art in Oct 2018 | 2-20% improvement over BERT | 5% degradation from BERT | 2-15% improvement over BERT |\n| Data | 16 GB BERT data (Books Corpus + Wikipedia). 3.3 Billion words. | 160 GB (16 GB BERT data + 144 GB additional) | 16 GB BERT data. 3.3 Billion words. | Base: 16 GB BERT data Large: 113 GB (16 GB BERT data + 97 GB additional). 33 Billion words. |\n| Method | BERT (Bidirectional Transformer with MLM and NSP) | BERT without NSP | BERT Distillation | Bidirectional Transformer with Permutation based modeling |\n\n\n\n\n\n<!-- PageNumber=\"10\" -->\n\nGPT-3の登場\n\nM\n\nGPT-3とは:Open AIが2020年にリリースした高精度言語AI。1750億パラメータ。 自然言語処理のさまざまなタスクで驚くような性能を発揮した。英語圏や研究者らの間では2020年夏にかなり話題に。 OpenAlは、イーロン·マスク氏や、Y-Combinatorのサム·アルトマン氏らが2015年に非営利組織として設立(現在は営利も大)\n\n事例1:質問応答\n\n事例2:知識による補完\n\n事例3:文章生成\n\n受信メール:あなたのプロジェクトに1000万\n\n円の投資で十分でしょうか? (一部略)\n\n入力: \\* ありがとう\\*いいえ\n\n\\*最低金額は1500万円 \\*1500万円から受 付可能 \\*市場は9兆円\n\n自動生成:\n\nご連絡有難うございます。弊社にご興味をお 持ちいただき、誠に嬉しく存じます。 大変申し訳ございませんが、私共の最低投 資受付金額は1500万円となっております。 1000万円が十分な金額かどうかは現時点で は判断いたしかねますが、引き続き議論させ てください。なお、ご存じかもしれませんが、市 場規模はおよそ9兆円です。\n\nQ: どんな動物が好きですか? A: 私の好きな動物は犬です。 Q: なぜですか? A: 犬は忠実でフレンドリーだから です。\n\n| | A | B |\n| - | - | - |\n| 1 | State Name | Population |\n| 2 | Illinois | 12.67M |\n| 3 | California | 39.51M |\n| 4 | Ohio | 11.69M |\n| 5 | Michigan | =gpt3(A1:B4,A5) |\n\n自然な会話ができる。\n\n“10.31M”と自動入力\n\n最低限の入力で丁寧語で のメール文章を生成\n\n\n\n<!-- PageNumber=\"11\" -->\n\nM\n\nスケール則 (scaling law) :極めて重要な法則\n===\n :selected:\n• データを増やし、計算能力を増やし、パラメータの数(モデルの容量)を増やせば、精度がどんどん上がる。\n :selected:\n• つまり、大きければ大きいほど性能があがる。\n :selected:\n• GPT-3は、ウェブの大きなデータ(4兆単語)で事前学習。1750億パラメータ。学習に数億\\~数十億円のコスト。\n\n<figure>\n\n![](figures/11)\n\n<!-- FigureContent=\"7 4.2 6 L =(D/5.4 · 1013)-0.095 5.6 一 L = (N/8.8 · 1013)-0.076 3.9 5 4.8 Test Loss 3.6 4.0 4 3.3 3.2 3- 3.0 L =(Cmin/2.3· 108)-0.050 2.4 - 2 2.7 10-9 10-7 10-5 10-3 10-1 101 108 109 105 107 109 Compute Dataset Size Parameters PF-days, non-embedding tokens non-embedding\" -->\n\n<figcaption>\n\nFigure 1 Language modeling performance improves smoothly as we increase the model size, datasetset\nsize, and amount of compute2 used for training. For optimal performance all three factors must be scaled\nup in tandem. Empirical performance has a power-law relationship with each individual factor when not\nbottlenecked by the other two.\n\n</figcaption>\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"12\" -->\n\n## ビッグテックの大規模化への競争\n\nM\n\n• 2020.7 GPT-3 by OpenAl (1750億パラメータ)\n\n• 2021.12 Gopher by DeepMind (2800億パラメータ)\n\n• 2022.5 Open Pretrained Transformer (OPT) by Meta (1750億パラメータ)\n :selected:\n• 2022.4 Pathways Laguage Model (PaLM) by Google (5400億パラメータ)\n\n• 完全に規模の戦争に。冗談がなぜ面白いかを解説することもできる。\n\n\n## Explaining a Joke\n\n\n\n\n## filename: test111.txt\n\n ## context 1. RAGシステム構築に興味を持っている​\n\nセッション:「Azure OpenAI Service と RAG について(基本)」のセッション(座学)を実施する​\n\n情報共有: 実装方法が分からない場合は以下を実施​\n\nMicrosoft Learnの関連ページの共有​\n\nGitHub レポジトリ(Solution Accelerator)の紹介​\n\nハンズオントレーニングの実施​\n\n2. RAGシステムを構築し始めている (困ってはない)​\n\nセッション:「RAGの精度向上のためのチューニングポイント」のセッション(座学)を実施する​\n\n3. RAGシステムを構築したが回答精度が悪くて困っている​\n\nヒアリング: 困っている点についてのヒアリングを実施する​\n\nセッション: 「RAGの精度向上のためのチューニングポイント」のセッション(座学)を提供する​\n\n技術Q&A: 困っている点についての技術Q&Aセッションを実施する​\n\nコワーク: 顧客からデータを共有してもらいSS/TSで手を動かして検証を行う(コワーク(Co-Work))​\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## Logical Inference\n\nInput: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods !\n\nModel Output: TPUs are a type of computer chip that Google uses for deep learning. A \"pod\" is a group of TPUs. A \"pod\" is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs .\n\nInput: Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. Going home next Tuesday!\n\nQuestion: Is it likely that Shelley will be near the Pacific Ocean this weekend? Model Output: The city with the famous market where they throw the fish is Seattle, Washington. Seattle is on the Pacific Ocean. Shelley is visiting Seattle, so she will be near the Pacific Ocean this weekend. The answer is \"yes\", it is likely that Shelley will be near the Pacific Ocean this weekend.\n\n\n\n<!-- PageNumber=\"13\" -->\n\n大規模言語モデル (Large Language Models; LLMs) より大きなモデルに\n===\n\n<figure>\n\n![](figures/12)\n\n<!-- FigureContent=\"GPT-4 (?)\n\nNumber of parameters\n\n(In Billion)\n\nM\n 10,000.00 Switch Transformer (1571B) 1,000.00 悟空2.0(1750B) :unselected: 100.00 GPT-3(175B) PaLM (540B) 10.00 Turning-NLG(17.2B) Megatron-LM (8.3B) 1.00 GPT-2(1.5B) 0.10 BERT-L (340M) ELMo(94M) 0.01 2018 2019 2020 2021 2022 2023\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"14\" -->\n\n\n\n\n\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n\n·ChatGPTの出現とその活用方法/影響\n\n·今後の社会/仕事への影響、日本の戦略\n\n\n\n<!-- PageNumber=\"15\" -->\n:unselected: :unselected:\nChatGPT\n===\n\n\n\nOpen AIは2022年11月30日にChatGPTを公開。 現在は無料公開中で、公開から1週間で100万ユーザ、2ヶ月で1億ユーザに到達。 その性能の高さから各所で話題に。 従来の大規模言語モデルよりも高度な意味理解と会話(チャット)が可能。 GPT-3 (とその後継のGPT-3.5) をベースにしている。\n\n<figure>\n\n![](figures/13)\n\n</figure>\n\n\n|||\n| - | - |\n| YU | 日本全体にイノベーションをもたらすにはどうすればいいですか? |\n| | 日本におけるイノベーションを促進するためには、政府がより効果的な政策を推進し、起業 家やビジネスに対する支援を強化することが重要です。また、教育システムを改革して、創 造的思考や問題解決の能力を高めることも必要です。さらに、企業が研究開発に投資する ことを奨励することも有益です。 |\n\n\n\n\n\n\n\n<!-- PageNumber=\"16\" -->\n\n\n\nオープンイノベーションについての会話例\n===\n\n| Reset Thread | YU | スタートアップによるオープンイノベーションについてどう思いますか? ||| |||\n| - | - | - | - |\n| \n| & Dark Mode (3) OpenAl Discord | | スタートアップによるオープンイノベーションは、新しいアイデアや技術を生み出すことに よって社会をより良いものにするための活動です。これは、企業や個人が独自の発明や技 | |\n| Learn More | | 術を公開し、他の人がそれを改善したり拡張したりすることで、技術や産業全体が向上す るというものです。私は、このような取り組みが、社会の発展と成長を促進するために非 常に重要な役割を果たすと考えています。 ||\n| [→ Log out ||||\n| | YU | スタートアップと大企業はどのような関係であるべきですか? | 了 |\n|| | スタートアップと大企業は、相互に補完的な関係にあるべきです。スタートアップは、新し 白 ワ いアイデアや技術を生み出すことで、産業や技術の発展を促進する役割を担っています。– 方で、大企業は、その規模や資金力を活かして、スタートアップが生み出したアイデアや技 術を拡大して普及させることができます。このような相互の協力関係は、産業の発展とイノ ベーションを促進するために非常に重要なものです。 ||\n|| YU | 大企業が具体的に何をしたら良いか教えてもらえますか? \n|| || | 大企業がスタートアップと協力するためには、様々な取り組みがあります。たとえば、大企 業は、スタートアップが生み出したアイデアや技術を採用することで、そのアイデアや技術 を拡大して普及させることができます。また、大企業は、スタートアップを投資すること で、その成長を支援することもできます。さらに、大企業は、スタートアップとの協力を通 じて、新しいビジネスモデルやサービスを開発することで、市場に新しい価値を提供するこ とができます。そのためには、大企業は、スタートアップとの接点を持つ担当者や部署を設 けるなどして、スタートアップとの協力を図る必要があります。 ||\n\n\n\n<!-- PageNumber=\"17\" -->\n\n\n\nChatGPTの学習方法\n\n\n## ChatGPTの学習は以下の3つのステップで構成されている\n\n\n## Step 1:教師あり学習\n\n·プロンプトとそれに対する適切な回答の ペアをアノテーター(人間) が考案 し、データセットを作成する\n\n·このデータセットを用いてGPT-3.5モデ ルをファインチューニングする\n\n<figure>\n\n![](figures/14)\n\n<!-- FigureContent=\"プロンプト:日本の SFT 首都は? 回答:東京です 0 . 自目目 . . データセット GPT-3.5モデル\" -->\n\n</figure>\n\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## ChatGPT\n\n• InstructGPTという先行モデルで用いられた「人間のフィードバ ックに基づいた強化学習」の考え方をChatGPTでも採用\n\n■ 文の良さを評価してくれる報酬モデルを新たに学習させて、 報酬が最大化するように強化学習を実施する\n\n\\- 有害なテキストを生成しないようにモデルを微調整\n\n· 会話データを用いてモデルのファインチューニングを行う\n\n■ アノテーターが擬似的な「ユーザーと AIの会話」のデータを 作成し、学習に活用\n\n\\- 会話ならではの砕けた表現などでも正しく意味理解し、 適切な回答の生成が可能\n\n\n\n\n\n<!-- PageNumber=\"19\" -->\n\n\n:unselected:\nChatGPTができること」自然言語におけるユースケース\n===\n\nM\n\n自然言語\n\nユースケース\n\nオリジナルが 人間のアウトプット\n\n<figure>\n\n![](figures/17)\n\n</figure>\n\n\nオリジナルが AIのアウトプット\n\n| 文章の 添削、校正 | 文法ミスだけでなく 内容の改善点まで 指摘 || | |\n| - | - | - | - | - |\n| 文章や 概念の要約 | 文字数を指定して 要約 || | |\n| 壁打ち、 ブレインストーミング | 「 \\~\\~ 」という考えの うち抜けている点を 指摘 || AIと人間で会話しな がらアイディエーション | |\n| リサーチ、 論点の洗い出し | | 「XX」について要点 だけ説明 | ディベート風に論点 を洗い出し | 表形式で比較表を 作成 |\n| アイデアの提案 | | SEO対策したタイト ルやキーワード形成 | 広告文の自動生成 | 何かに なりきって答える |\n||\n||| | | || 結婚式のスピーチの アウトライン作成 | 人気の出るブログの 内容案の提案 | 例題や乱数などの 生成 |\n||| … | … | … |\n\n従来と同じタスクだが、 精度が大幅に向上\n\nChatGPTの卓越したコ ミュニケーション精度と 圧倒的な知識量(デー 夕量,パラメータ数)か ら、以前では決してでき なかったことまでできる ようになっている。\n\n\n\n\n\n<!-- PageNumber=\"20\" -->\n\nChatGPTへの対応\n===\n\n海外では既に学校や学会でChatGPTの使い方に対して対応\n\nM\n\n• ニューヨーク、シアトル州の公立学校においてChatGPTの宿題への利用を禁止\n\n● 一方で一部の教育機関では、ChatGPTを教育のツールとして積極的に活用しようとする動き 例えば、英語学習において、ChatGPTを使って文章を作成する練習をすることで、自然な英語表 現を身につけることができる\n\n<figure>\n\n![](figures/18)\n\n<!-- FigureContent=\"学校\" -->\n\n</figure>\n\n\n\\- I\n\nI\n\n科学論文\n\n● ChatGPTを活用して科学論文を執筆することを禁止にするとICMLなどが発表\n\n● 一方で文章の編集や推敲に活用することは問題ないとされている\n\n\n\n<!-- PageNumber=\"21\" -->\n\n学校でのChatGPTの利用について\n\nM\n\neuronews.next\n\nBIZTECH NEWS\n\nMONEY\n\nWORK MOBILITY\n\nHEALTH HOME\n\nOPINION\n\nSERIES √\n\nThe New york Times\n\nTHE SHIFT\n\nDon't Ban ChatGPT in Schools. Teach With It.\n\nOpenAl's new chatbot is raising fears of cheating on homework, but its potential as an educational tool outweighs its risks.\n\nRecently, I gave a talk to a group of K-12 teachers and public school administrators in New York. The topic was artificial intelligence, and how schools would need to adapt to prepare students for a future filled with all kinds of capable A.I. tools.\n\nBut it turned out that my audience cared about only one A.I. tool: ChatGPT, the buzzy chatbot developed by OpenAI that is capable of writing cogent essays, solving science and math problems and producing working computer code.\n\nChatGPT is new - it was released in late November - but it has already sent many educators into a panic. Students are using it to write their assignments, passing off A.I .- generated essays and problem sets as their own. Teachers and school administrators have been scrambling to catch students using the tool to cheat, and they are fretting about the havoc ChatGPT could wreak on their lesson plans. (Some publications have declared, perhaps a bit prematurely, that ChatGPT has killed homework altogether.)\n\nWORK\n\n\n## Students are using ChatGPT to do their homework. Should schools ban Al tools, or embrace them?\n\nBy Oceane Duboust & Camille Bello . Updated: 28/01/2023\n\nIs the end of homework near? As new powerful artificial intelligence (AI) tools like ChatGPT take the Internet by storm, teachers concerned with Al-driven cheating are questioning their teaching and assessment methods.\n\nChatGPT, the most powerful Al language model ever developed by the company OpenAl, is capable of generating natural-sounding text on demand, including in a specific style or in several languages, in just a few seconds.\n\nThe quality of the copy it produces is sufficient to impress teachers in secondary and higher education, and even researchers.\n\n\"Young or not, we are all amazed at how quickly and relevantly it responds,\" Cecile Cathelin, a teacher at a high school in the French city of Tours, told Euronews Next.\n\nRELATED ● ChatGPT: Why the human-like Al chatbot suddenly has everyone talking\n\nThe use of Al tools in copywriting has sparked an outcry around the world. In the United States, public schools in New York and Seattle have decided to block ChatGPT from their devices and\n\nWiFi networks\n\nhttps://www.euronews.com/hext/2023/01/28/students-are-using-chatgpt-to-do-their-homework-should-schools-ban-ai-tools-or-embrace-the https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html\n\n©MATSUO LAB, THE UNIVERSITY OF TOKYO\n\n<!-- PageNumber=\"22\" -->\n\nM\n\n\n\n\n## The Guardian\n\n\n\n\n"}
{"query": "自然言語処理（NLP）とは何ですか？", "ground_truth": "自然言語処理（NLP）は、人間の言語を理解し、解釈し、生成するためのコンピュータサイエンスと人工知能の一分野です。テキストの解析、機械翻訳、感情分析、チャットボットの開発などに利用されます。", "response": "自然言語処理（NLP）とは、人間の言語をコンピュータで理解、解釈、生成する技術のことを指します。NLPは、テキストや音声データを処理し、意味を理解するためのアルゴリズムやモデルを使用します。具体的には、文章の文法チェック、感情分析、機械翻訳、質問応答システムなど、さまざまな応用があります。\n\nNLPの分野では、特に2018年ごろからディープラーニング技術の進化により急速に性能が向上しました。例えば、GLUE（General Language Understanding Evaluation）というベンチマークでは、NLPモデルの精度が人間の精度を超える成果が報告されています。また、トランスフォーマーという技術が鍵となり、多くのタスクで最新の性能を達成しています。[20230217_AIの進化と日本の戦略_松尾研.pdf]", "context": "## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context 目的の動作を行うように、重みを調整する(誤差逆伝播)\n|+1層のユニットjの値:\nN\n<figure>\n![](figures/6)\n<!-- FigureContent=\"x1+1 = 0 .l+1 i=1 - 00000 :unselected: :unselected: :unselected: :unselected: :unselected: 00000 :unselected: :unselected: :unselected: :unselected: :unselected: :unselected: 0000 :unselected: :unselected: :unselected: :unselected: :unselected: - 入力 X :unselected: 出力 y -\" -->\n</figure>\n :unselected: :unselected: :unselected:\n<!-- PageNumber=\"7\" -->\n:selected:\nM\nディープラーニングによる自然言語処理が2018年ごろから急速に性能向上\n===\n2012年にDeep Learningが画像認識で大きなブレークスルー 2015年には画像·音声分野で人間を超える精度を達成\nGLUE (General Language Understanding Evaluation)\n| データセット | 概要 |\n| - | - |\n| CoLA | 正しい文法で書かれているかの二値分類 |\n| SST-2 | 映画レビューのpos/neg判定。文を構文末解析し、各フレー ズごとにpos/negが振られているが、GLUEでは文単位のもの のみを対象としている。 |\n| MRPC | 2文が同じ意味かどうかの二値分類 |\n| STS-B | 2文の類似度を1 -- 5で評価 |\n| QQP | 2つの質問文が同じ意味かどうかの二値分類 |\n| MNLI | 前提の文と仮説の文に対して、含意的/矛盾/無関係の3クラス 分類。 |\n| QNLI | SQUADの文章と質問のペアを、文章中の各文と質問のペアに し,その各文に質問の回答が含まれているかの二値分類を行 う。 |\n| RTE | 2文の含意の二値分類 |\n<figure>\n![](figures/7)\n</figure>\n自然言語処理 (NLP)では、2018年から急激に 精度が向上し、GLUE評価で人間の精度を超えた\nGLUE (NLPベンチマーク)の精度推移\n<figure>\n![](figures/8)\n<!-- FigureContent=\"90 人間:87.1 88.4 80 80.2 70 70 65.6 60 58.6 50 2013年 2017年以前 2018年3月 2018年10月 CBoW LSTM+Attn ELMo BERT XLNet T5\" -->\n</figure>\nわずか2年で約25%向上\n<!-- PageNumber=\"○○DO\" -->\n<!-- PageNumber=\"8\" -->\nM\n鍵となる技術:トランスフォーマー(L. Kaiser et al., 2017)\n===\n :selected:\n· 有名な「Attention is All You Need」論文。Googleの研究者ら。\n●「アテンション」という機構を大規模に使ったトランスフォーマーを提案。\nー アテンション(自己注意機構) : ニューラルネットワーク中のどこの情報をどのよ\nうに使うか自体を学習することができる。\nー トランスフォーマーは、マルチヘッドのセルフアテンションを多層に重ねたもの。\n\\- 多くのタスクでSOTA(最新性能)を出した。\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context 目的の動作を行うように、重みを調整する(誤差逆伝播)\n|+1層のユニットjの値:\nN\n<figure>\n![](figures/6)\n<!-- FigureContent=\"x1+1 = 0 .l+1 i=1 - 00000 :unselected: :unselected: :unselected: :unselected: :unselected: 00000 :unselected: :unselected: :unselected: :unselected: :unselected: :unselected: 0000 :unselected: :unselected: :unselected: :unselected: :unselected: - 入力 X :unselected: 出力 y -\" -->\n</figure>\n :unselected: :unselected: :unselected:\n<!-- PageNumber=\"7\" -->\n:selected:\nM\nディープラーニングによる自然言語処理が2018年ごろから急速に性能向上\n===\n2012年にDeep Learningが画像認識で大きなブレークスルー 2015年には画像·音声分野で人間を超える精度を達成\nGLUE (General Language Understanding Evaluation)\n| データセット | 概要 |\n| - | - |\n| CoLA | 正しい文法で書かれているかの二値分類 |\n| SST-2 | 映画レビューのpos/neg判定。文を構文末解析し、各フレー ズごとにpos/negが振られているが、GLUEでは文単位のもの のみを対象としている。 |\n| MRPC | 2文が同じ意味かどうかの二値分類 |\n| STS-B | 2文の類似度を1 -- 5で評価 |\n| QQP | 2つの質問文が同じ意味かどうかの二値分類 |\n| MNLI | 前提の文と仮説の文に対して、含意的/矛盾/無関係の3クラス 分類。 |\n| QNLI | SQUADの文章と質問のペアを、文章中の各文と質問のペアに し,その各文に質問の回答が含まれているかの二値分類を行 う。 |\n| RTE | 2文の含意の二値分類 |\n<figure>\n![](figures/7)\n</figure>\n自然言語処理 (NLP)では、2018年から急激に 精度が向上し、GLUE評価で人間の精度を超えた\nGLUE (NLPベンチマーク)の精度推移\n<figure>\n![](figures/8)\n<!-- FigureContent=\"90 人間:87.1 88.4 80 80.2 70 70 65.6 60 58.6 50 2013年 2017年以前 2018年3月 2018年10月 CBoW LSTM+Attn ELMo BERT XLNet T5\" -->\n</figure>\nわずか2年で約25%向上\n<!-- PageNumber=\"○○DO\" -->\n<!-- PageNumber=\"8\" -->\nM\n鍵となる技術:トランスフォーマー(L. Kaiser et al., 2017)\n===\n :selected:\n· 有名な「Attention is All You Need」論文。Googleの研究者ら。\n●「アテンション」という機構を大規模に使ったトランスフォーマーを提案。\nー アテンション(自己注意機構) : ニューラルネットワーク中のどこの情報をどのよ\nうに使うか自体を学習することができる。\nー トランスフォーマーは、マルチヘッドのセルフアテンションを多層に重ねたもの。\n\\- 多くのタスクでSOTA(最新性能)を出した。\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## Logical Inference\n\nInput: Did you see that Google just hired an eloquent whale for their TPU team? It showed them how to communicate between two different pods !\n\nModel Output: TPUs are a type of computer chip that Google uses for deep learning. A \"pod\" is a group of TPUs. A \"pod\" is also a group of whales. The joke is that the whale is able to communicate between two groups of whales, but the speaker is pretending that the whale is able to communicate between two groups of TPUs .\n\nInput: Shelley is from Virginia, but is visiting that city with that famous market where they throw the fish. Going home next Tuesday!\n\nQuestion: Is it likely that Shelley will be near the Pacific Ocean this weekend? Model Output: The city with the famous market where they throw the fish is Seattle, Washington. Seattle is on the Pacific Ocean. Shelley is visiting Seattle, so she will be near the Pacific Ocean this weekend. The answer is \"yes\", it is likely that Shelley will be near the Pacific Ocean this weekend.\n\n\n\n<!-- PageNumber=\"13\" -->\n\n大規模言語モデル (Large Language Models; LLMs) より大きなモデルに\n===\n\n<figure>\n\n![](figures/12)\n\n<!-- FigureContent=\"GPT-4 (?)\n\nNumber of parameters\n\n(In Billion)\n\nM\n 10,000.00 Switch Transformer (1571B) 1,000.00 悟空2.0(1750B) :unselected: 100.00 GPT-3(175B) PaLM (540B) 10.00 Turning-NLG(17.2B) Megatron-LM (8.3B) 1.00 GPT-2(1.5B) 0.10 BERT-L (340M) ELMo(94M) 0.01 2018 2019 2020 2021 2022 2023\" -->\n\n</figure>\n\n\n\n\n\n\n<!-- PageNumber=\"14\" -->\n\n\n\n\n\n·AI·ディープラーニングの進化と大規模言語モデル (LLM)\n\n·ChatGPTの出現とその活用方法/影響\n\n·今後の社会/仕事への影響、日本の戦略\n\n\n\n<!-- PageNumber=\"15\" -->\n:unselected: :unselected:\nChatGPT\n===\n\n\n\nOpen AIは2022年11月30日にChatGPTを公開。 現在は無料公開中で、公開から1週間で100万ユーザ、2ヶ月で1億ユーザに到達。 その性能の高さから各所で話題に。 従来の大規模言語モデルよりも高度な意味理解と会話(チャット)が可能。 GPT-3 (とその後継のGPT-3.5) をベースにしている。\n\n<figure>\n\n![](figures/13)\n\n</figure>\n\n\n|||\n| - | - |\n| YU | 日本全体にイノベーションをもたらすにはどうすればいいですか? |\n| | 日本におけるイノベーションを促進するためには、政府がより効果的な政策を推進し、起業 家やビジネスに対する支援を強化することが重要です。また、教育システムを改革して、創 造的思考や問題解決の能力を高めることも必要です。さらに、企業が研究開発に投資する ことを奨励することも有益です。 |\n\n\n\n\n\n\n\n<!-- PageNumber=\"16\" -->\n\n\n\nオープンイノベーションについての会話例\n===\n\n| Reset Thread | YU | スタートアップによるオープンイノベーションについてどう思いますか? ||| |||\n| - | - | - | - |\n| \n| & Dark Mode (3) OpenAl Discord | | スタートアップによるオープンイノベーションは、新しいアイデアや技術を生み出すことに よって社会をより良いものにするための活動です。これは、企業や個人が独自の発明や技 | |\n| Learn More | | 術を公開し、他の人がそれを改善したり拡張したりすることで、技術や産業全体が向上す るというものです。私は、このような取り組みが、社会の発展と成長を促進するために非 常に重要な役割を果たすと考えています。 ||\n| [→ Log out ||||\n| | YU | スタートアップと大企業はどのような関係であるべきですか? | 了 |\n|| | スタートアップと大企業は、相互に補完的な関係にあるべきです。スタートアップは、新し 白 ワ いアイデアや技術を生み出すことで、産業や技術の発展を促進する役割を担っています。– 方で、大企業は、その規模や資金力を活かして、スタートアップが生み出したアイデアや技 術を拡大して普及させることができます。このような相互の協力関係は、産業の発展とイノ ベーションを促進するために非常に重要なものです。 ||\n|| YU | 大企業が具体的に何をしたら良いか教えてもらえますか? \n|| || | 大企業がスタートアップと協力するためには、様々な取り組みがあります。たとえば、大企 業は、スタートアップが生み出したアイデアや技術を採用することで、そのアイデアや技術 を拡大して普及させることができます。また、大企業は、スタートアップを投資すること で、その成長を支援することもできます。さらに、大企業は、スタートアップとの協力を通 じて、新しいビジネスモデルやサービスを開発することで、市場に新しい価値を提供するこ とができます。そのためには、大企業は、スタートアップとの接点を持つ担当者や部署を設 けるなどして、スタートアップとの協力を図る必要があります。 ||\n\n\n\n<!-- PageNumber=\"17\" -->\n\n\n\nChatGPTの学習方法\n\n\n## ChatGPTの学習は以下の3つのステップで構成されている\n\n\n## Step 1:教師あり学習\n\n·プロンプトとそれに対する適切な回答の ペアをアノテーター(人間) が考案 し、データセットを作成する\n\n·このデータセットを用いてGPT-3.5モデ ルをファインチューニングする\n\n<figure>\n\n![](figures/14)\n\n<!-- FigureContent=\"プロンプト:日本の SFT 首都は? 回答:東京です 0 . 自目目 . . データセット GPT-3.5モデル\" -->\n\n</figure>\n\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## ChatGPT\n\n• InstructGPTという先行モデルで用いられた「人間のフィードバ ックに基づいた強化学習」の考え方をChatGPTでも採用\n\n■ 文の良さを評価してくれる報酬モデルを新たに学習させて、 報酬が最大化するように強化学習を実施する\n\n\\- 有害なテキストを生成しないようにモデルを微調整\n\n· 会話データを用いてモデルのファインチューニングを行う\n\n■ アノテーターが擬似的な「ユーザーと AIの会話」のデータを 作成し、学習に活用\n\n\\- 会話ならではの砕けた表現などでも正しく意味理解し、 適切な回答の生成が可能\n\n\n\n\n\n<!-- PageNumber=\"19\" -->\n\n\n:unselected:\nChatGPTができること」自然言語におけるユースケース\n===\n\nM\n\n自然言語\n\nユースケース\n\nオリジナルが 人間のアウトプット\n\n<figure>\n\n![](figures/17)\n\n</figure>\n\n\nオリジナルが AIのアウトプット\n\n| 文章の 添削、校正 | 文法ミスだけでなく 内容の改善点まで 指摘 || | |\n| - | - | - | - | - |\n| 文章や 概念の要約 | 文字数を指定して 要約 || | |\n| 壁打ち、 ブレインストーミング | 「 \\~\\~ 」という考えの うち抜けている点を 指摘 || AIと人間で会話しな がらアイディエーション | |\n| リサーチ、 論点の洗い出し | | 「XX」について要点 だけ説明 | ディベート風に論点 を洗い出し | 表形式で比較表を 作成 |\n| アイデアの提案 | | SEO対策したタイト ルやキーワード形成 | 広告文の自動生成 | 何かに なりきって答える |\n||\n||| | | || 結婚式のスピーチの アウトライン作成 | 人気の出るブログの 内容案の提案 | 例題や乱数などの 生成 |\n||| … | … | … |\n\n従来と同じタスクだが、 精度が大幅に向上\n\nChatGPTの卓越したコ ミュニケーション精度と 圧倒的な知識量(デー 夕量,パラメータ数)か ら、以前では決してでき なかったことまでできる ようになっている。\n\n\n\n\n\n<!-- PageNumber=\"20\" -->\n\nChatGPTへの対応\n===\n\n海外では既に学校や学会でChatGPTの使い方に対して対応\n\nM\n\n• ニューヨーク、シアトル州の公立学校においてChatGPTの宿題への利用を禁止\n\n● 一方で一部の教育機関では、ChatGPTを教育のツールとして積極的に活用しようとする動き 例えば、英語学習において、ChatGPTを使って文章を作成する練習をすることで、自然な英語表 現を身につけることができる\n\n<figure>\n\n![](figures/18)\n\n<!-- FigureContent=\"学校\" -->\n\n</figure>\n\n\n\\- I\n\nI\n\n科学論文\n\n● ChatGPTを活用して科学論文を執筆することを禁止にするとICMLなどが発表\n\n● 一方で文章の編集や推敲に活用することは問題ないとされている\n\n\n\n<!-- PageNumber=\"21\" -->\n\n学校でのChatGPTの利用について\n\nM\n\neuronews.next\n\nBIZTECH NEWS\n\nMONEY\n\nWORK MOBILITY\n\nHEALTH HOME\n\nOPINION\n\nSERIES √\n\nThe New york Times\n\nTHE SHIFT\n\nDon't Ban ChatGPT in Schools. Teach With It.\n\nOpenAl's new chatbot is raising fears of cheating on homework, but its potential as an educational tool outweighs its risks.\n\nRecently, I gave a talk to a group of K-12 teachers and public school administrators in New York. The topic was artificial intelligence, and how schools would need to adapt to prepare students for a future filled with all kinds of capable A.I. tools.\n\nBut it turned out that my audience cared about only one A.I. tool: ChatGPT, the buzzy chatbot developed by OpenAI that is capable of writing cogent essays, solving science and math problems and producing working computer code.\n\nChatGPT is new - it was released in late November - but it has already sent many educators into a panic. Students are using it to write their assignments, passing off A.I .- generated essays and problem sets as their own. Teachers and school administrators have been scrambling to catch students using the tool to cheat, and they are fretting about the havoc ChatGPT could wreak on their lesson plans. (Some publications have declared, perhaps a bit prematurely, that ChatGPT has killed homework altogether.)\n\nWORK\n\n\n## Students are using ChatGPT to do their homework. Should schools ban Al tools, or embrace them?\n\nBy Oceane Duboust & Camille Bello . Updated: 28/01/2023\n\nIs the end of homework near? As new powerful artificial intelligence (AI) tools like ChatGPT take the Internet by storm, teachers concerned with Al-driven cheating are questioning their teaching and assessment methods.\n\nChatGPT, the most powerful Al language model ever developed by the company OpenAl, is capable of generating natural-sounding text on demand, including in a specific style or in several languages, in just a few seconds.\n\nThe quality of the copy it produces is sufficient to impress teachers in secondary and higher education, and even researchers.\n\n\"Young or not, we are all amazed at how quickly and relevantly it responds,\" Cecile Cathelin, a teacher at a high school in the French city of Tours, told Euronews Next.\n\nRELATED ● ChatGPT: Why the human-like Al chatbot suddenly has everyone talking\n\nThe use of Al tools in copywriting has sparked an outcry around the world. In the United States, public schools in New York and Seattle have decided to block ChatGPT from their devices and\n\nWiFi networks\n\nhttps://www.euronews.com/hext/2023/01/28/students-are-using-chatgpt-to-do-their-homework-should-schools-ban-ai-tools-or-embrace-the https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html\n\n©MATSUO LAB, THE UNIVERSITY OF TOKYO\n\n<!-- PageNumber=\"22\" -->\n\nM\n\n\n\n\n## The Guardian\n\n\n\n\n## filename: 20230217_AIの進化と日本の戦略_松尾研.pdf\n\n ## context ## 日本の戦略\n\n\n\nChatGPTの出現により大きく仕事のやり方が変わる。AIの「新しい時代」に入った。\n\n多くの人が、この技術はすごいと理解し、世の中が変わると確信した。それによって、本当に変化が起こる。資金も人も流れ る。ChatGPTにより、新しい時代に入ることが確定した。賽は投げられた。\n\nそのときに、日本としてどうすべきか。基本的には3つの戦略。新しい時代なので、やり方によっては(厳しい戦いだが) 勝 てるチャンスがあるということでもある。ただし、急ぐ必要がある。\n\n\n### 1\\. 大規模言語モデルを自ら開発する\n\n■ 数百億円あれば同じようなものは作れる(ただし、その間に相手はもっと先に行く。)\n\n\\- 今後のインパクトの大きさを考えれば、この戦いに参入するチケットとしては安い。この機会が開いているウィンドウは短い。\n\n\n## 2\\. APIを使いサービスを作ることを奨励する\n\n\\- ChatGPTなどのAPIを使って、ローカライズした専用アプリ、専用ソフトウェアが多く出現。国内の市場になるので、最低限ここはし :unselected: っかり伸ばすべき。\n\n\\- 一方Apple Store等と同じく、手数料を払い続けないといけない。\n\n\n## 3\\. ユーザとしての活用を促進する\n\n\\- DXが進んでいない現状において、言語による指示ができることは、DXの決め手になる可能性はある\n\n■ つまり、DXにおけるリープフロッグ。(アフリカに固定電話が入ってないのに携帯が入ったように。)\n\n\n\n<!-- PageNumber=\"30\" -->\n\nM\n\n<figure>\n\n![](figures/23)\n\n<!-- FigureContent=\"W 松尾研究室 MATSUO LAB THE UNIVERSITY OF TOKYO\" -->\n\n</figure>\n\n\n\n\n\n"}
